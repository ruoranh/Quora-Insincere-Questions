{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text manipulation\n",
    "import re\n",
    "import string\n",
    "\n",
    "# Data management\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import *\n",
    "import scipy\n",
    "\n",
    "# NLP\n",
    "import nltk\n",
    "import nltk.collocations as collocations\n",
    "from nltk.tag import tnt\n",
    "import spacy\n",
    "\n",
    "# modelling\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.cluster import MeanShift\n",
    "\n",
    "#visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
       "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
       "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
       "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1306122, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of insincere questions: 80810\n",
      "No. of sincere questions: 1225312\n",
      "% of insincere questions: 0.06187017751787352\n",
      "Null score: 0.9381298224821265\n"
     ]
    }
   ],
   "source": [
    "no_insincere = train[train['target']==1].target.count()\n",
    "no_sincere = train[train['target']==0].target.count()\n",
    "\n",
    "print('No. of insincere questions:', no_insincere)\n",
    "print('No. of sincere questions:', no_sincere)\n",
    "print('% of insincere questions:', train.target.mean())\n",
    "print('Null score:', 1- train.target.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# remove digits\n",
    "clean_questions = [''.join(c for c in q if not c.isdigit()) for q in train.question_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing all identity labels each question with a common labels\n",
    "def labels_to_question(data, label_list, label_type):\n",
    "         \n",
    "    new_data = []\n",
    "    \n",
    "    # For every questions\n",
    "    i_data = 0\n",
    "    for i_data in range(len(data)):\n",
    "        question = data[i_data].lower()\n",
    "        output = []\n",
    "        \n",
    "        # compare each label to question\n",
    "        for label in label_list:\n",
    "\n",
    "            if label in question:\n",
    "\n",
    "                que_t = nltk.word_tokenize(question)\n",
    "                lab_t = nltk.word_tokenize(label)\n",
    "\n",
    "                i_que = 0\n",
    "                while i_que < len(que_t):\n",
    "                    i_lab = 0\n",
    "                    \n",
    "                    # If current token is same as first label token, continue compare rest of the tokens. \n",
    "                    if que_t[i_que] == lab_t[0]:\n",
    "                        que_t[i_que] = label_type\n",
    "                        i_lab += 1\n",
    "                        i_que += 1\n",
    "\n",
    "                        # Remove trailing question tokens if they match trailing label tokens\n",
    "                        while i_lab < len(lab_t):\n",
    "                            if que_t[i_que] == lab_t[i_lab]:\n",
    "                                que_t.pop(i_que)\n",
    "                                i_lab += 1\n",
    "                            else:\n",
    "                                break\n",
    "#                     elif que_t[i_que] == lab_t[0]:\n",
    "#                         print('Question: ',question, i_data)\n",
    "#                         print('label: ', label)\n",
    "                    i_que += 1\n",
    "                question = ' '.join(que_t)\n",
    "#                 print('after: ', question)\n",
    "#                 print('label: ', label)\n",
    "        new_data.append(question)                   \n",
    "        if i_data % 1000 == 0:\n",
    "            clear_output(wait=True)\n",
    "            display(i_data)\n",
    "    return new_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('nationalities.txt', 'r')\n",
    "nationalities = []\n",
    "for n in f:\n",
    "    nationalities.append(n.strip().lower())\n",
    "f.close()\n",
    "nationalities = set(nationalities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identity groupd filters, created from online lists, most frequent insincere words and manual editing.\n",
    "ID_filter = pd.read_csv('ID_filter.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RELIGIOUS_ID</th>\n",
       "      <th>RACIAL_ID</th>\n",
       "      <th>NATIONAL_ID</th>\n",
       "      <th>NATIONALITY_ID</th>\n",
       "      <th>GENDER_ID</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Political_groups</th>\n",
       "      <th>Political_figure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>buddhist</td>\n",
       "      <td>white people</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Afghans</td>\n",
       "      <td>girls</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trump supporters</td>\n",
       "      <td>donald trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>catholic</td>\n",
       "      <td>black people</td>\n",
       "      <td>Albania</td>\n",
       "      <td>Albanians</td>\n",
       "      <td>boys</td>\n",
       "      <td>NaN</td>\n",
       "      <td>democrate</td>\n",
       "      <td>president trump</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  RELIGIOUS_ID     RACIAL_ID  NATIONAL_ID NATIONALITY_ID GENDER_ID  \\\n",
       "0     buddhist  white people  Afghanistan        Afghans     girls   \n",
       "1     catholic  black people      Albania      Albanians      boys   \n",
       "\n",
       "   Unnamed: 5  Political_groups Political_figure  \n",
       "0         NaN  trump supporters     donald trump  \n",
       "1         NaN         democrate  president trump  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID_filter.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "religious_ID = ID_filter.RELIGIOUS_ID.dropna()\n",
    "racial_ID = ID_filter.RACIAL_ID.dropna()\n",
    "national_ID = ID_filter.NATIONAL_ID.dropna()\n",
    "nationality_ID = ID_filter.NATIONALITY_ID.dropna()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1306000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clean_questions = labels_to_question(clean_questions, religious_ID, 'RELIGIOUS_ID')\n",
    "clean_questions = labels_to_question(clean_questions, racial_ID, 'RACIAL_ID')\n",
    "clean_questions = labels_to_question(clean_questions, national_ID, 'NATIONAL_ID')\n",
    "clean_questions = labels_to_question(clean_questions, nationality_ID, 'NATIONALITY_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['today REPLACED will REPLACED taxes', 'how did REPLACED manage this']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# q_sample = ['today united states will raise taxes', 'How did donald trump junior manage this']\n",
    "# label_sample = ('raise','united states', 'donald trump junior')\n",
    "# temp = labels_to_question(q_sample, label_sample, 'REPLACED')\n",
    "# temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = list(nltk.corpus.stopwords.words('english')) + list(string.punctuation) + [\"''\", '``','’','“','”', \"'s\", \"'d\", \"'ll\", \"'t\", \"n't\", \"ca\", 'wo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# remove stop words and lower all characters\n",
    "clean_questions = [' '.join(w for w in nltk.word_tokenize(q.lower()) if w not in stopwords) for q in clean_questions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1306122"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Do you have an adopted dog, how would you encourage people to adopt and not shop?'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.question_text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['quebec nationalists see province nation',\n",
       " 'adopted dog would encourage people adopt shop',\n",
       " 'velocity affect time velocity affect space geometry',\n",
       " 'otto von guericke used magdeburg hemispheres',\n",
       " 'convert montra helicon mountain bike changing tyres',\n",
       " 'gaza slowly becoming auschwitz dachau treblinka palestinians',\n",
       " 'quora automatically ban conservative opinions reported liberal views',\n",
       " 'crazy wash wipe groceries germs everywhere',\n",
       " 'thing dressing moderately different dressing modestly',\n",
       " 'ever phase wherein became ignorant people loved completely disregarding feelings/lives get something go way feel temporarily ease things change']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_questions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions and pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vect_trans(vectorizer, X_train, X_test):\n",
    "    # can also take a transformer\n",
    "    vect = vectorizer\n",
    "    vect.fit(X_train)\n",
    "    return vect.transform(X_train), vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultinominalNB function for printing scores and storing into df.\n",
    "def model_score(model, X_train, X_test, y_train, y_test, score_df, model_label):\n",
    "    estimator = model\n",
    "    estimator.fit(X_train, y_train)\n",
    "    test_score =  estimator.score(X_test, y_test)\n",
    "    f1 = f1_score(y_test, estimator.predict(X_test))\n",
    "    \n",
    "    print('Train Accuracy :', estimator.score(X_train, y_train))\n",
    "    print('Test Accuracy:', test_score)\n",
    "    print('Test F1 score:', f1)\n",
    "    score_df.loc[model_label, 'Test_Accuracy'] = test_score\n",
    "    score_df.loc[model_label, 'Test_F1_score'] = f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validate function for printing scores and storing into df.\n",
    "def cv_score(model, X, y, model_label,  cv=5, ):    \n",
    "    \n",
    "    # instantiating model\n",
    "    estimator = model\n",
    "    \n",
    "    cv_result = cross_validate(estimator, X, y, cv = cv, n_jobs=-1, scoring=['accuracy', 'f1'])\n",
    "    \n",
    "    print('Test Accuracy Mean:',cv_result['test_accuracy'].mean())\n",
    "    print('Test Accuracy STD:',cv_result['test_accuracy'].std())\n",
    "    print('Test F1:', cv_result['test_f1'].mean())\n",
    "    score_df.loc[model_label, 'CV_Accuracy'] = cv_result['test_accuracy'].mean()\n",
    "    score_df.loc[model_label, 'CV_Acc_STD'] = cv_result['test_accuracy'].std()\n",
    "    score_df.loc[model_label, 'CV_F1_score'] = cv_result['test_f1'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV function, auto display best score and parameters and storing in df\n",
    "def gridcv(model, X, y, params, cv= 5 ):\n",
    "    \n",
    "    # instantiating model can also be a pipeline\n",
    "    estimator = model\n",
    "    \n",
    "    gridcv = GridSearchCV(estimator=estimator, param_grid=params, cv = cv, verbose=10, n_jobs=6)\n",
    "    gridcv.fit(X, y)\n",
    "    \n",
    "    print(gridcv.best_params_)\n",
    "    print(gridcv.best_score_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer pipeline and parameters\n",
    "pipeCVNB = Pipeline([('CV',CountVectorizer(stop_words=stopwords)), \n",
    "                    ('NB',MultinomialNB())])\n",
    "\n",
    "paramsCVNB = {'CV__max_df':(1.0, 0.9, 0.8, 0.7),\n",
    "       'CV__min_df': (1, 2, 0.01 , 0.1, 0.2),\n",
    "         'CV__ngram_range':((1,1), (1,2), (1,3))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TfidfVectorizer pipeline and parameters\n",
    "pipeTVNB = Pipeline([('TV',TfidfVectorizer(stop_words=stopwords)), \n",
    "                    ('NB',MultinomialNB())])\n",
    "\n",
    "paramsTVNB = {'TV__max_df':(1.0, 0.9, 0.8, 0.7, 0.6),\n",
    "       'TV__min_df': (1, 2, 0.01, 0.05, 0.1),\n",
    "         'TV__ngram_range':((1,1), (1,2), (1,3), (2,2), (2,3))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Default count vectorizer on raw text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 30.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(train.question_text, train.target,\n",
    "                                                                    stratify=train.target, random_state = 495)\n",
    "\n",
    "X_train_raw_t, X_test_raw_t=  vect_trans(CountVectorizer(), X_train_raw, X_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.9350739237089765\n",
      "Test Accuracy: 0.9344135778838762\n",
      "Test F1 score: 0.5646092542896641\n",
      "Test Accuracy Mean: 0.9321614838567932\n",
      "Test Accuracy STD: 0.0005228593021778298\n",
      "Test F1: 0.5489215714930169\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>Test_F1_score</th>\n",
       "      <th>CV_Accuracy</th>\n",
       "      <th>CV_Acc_STD</th>\n",
       "      <th>CV_F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Raw_token_NB</th>\n",
       "      <td>0.934414</td>\n",
       "      <td>0.564609</td>\n",
       "      <td>0.932161</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.548922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Test_Accuracy  Test_F1_score  CV_Accuracy  CV_Acc_STD  \\\n",
       "Raw_token_NB       0.934414       0.564609     0.932161    0.000523   \n",
       "\n",
       "              CV_F1_score  \n",
       "Raw_token_NB     0.548922  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model_label = 'Raw_token_NB'\n",
    "\n",
    "model_score(model, X_train_raw_t, X_test_raw_t, y_train_raw, y_test_raw, score_df, model_label)\n",
    "cv_score(model, X_train_raw_t, y_train_raw, model_label)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.9350739237089765\n",
      "test score: 0.9344135778838762\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_raw_t, y_train_raw)  \n",
    "test_score =  nb.score(X_test_raw_t, y_test_raw)\n",
    "print('train score:', nb.score(X_train_raw_t, y_train_raw))\n",
    "print('test score:', test_score)\n",
    "y_pred = nb.predict(X_test_raw_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5646092542896641\n",
      "0.7645724512273393\n",
      "0.9344135778838762\n",
      "0.9397915566837656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[291229,  15099],\n",
       "       [  6317,  13886]], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f1_score(y_test_raw, y_pred) )\n",
    "print(f1_score(y_test_raw, y_pred, average='macro') )\n",
    "print(f1_score(y_test_raw, y_pred, average='micro') )\n",
    "print(f1_score(y_test_raw, y_pred, average='weighted') )\n",
    "confusion_matrix(y_test_raw, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Token and Ngram modelling on cleaned data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = clean_questions\n",
    "y = train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state = 495)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokens only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_t, X_test_t=  vect_trans(CountVectorizer(max_df=1.0, min_df=1, ngram_range=(1,1)), X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.937569863340925\n",
      "Test Accuracy: 0.9369248249017704\n",
      "Test F1 score: 0.553018794218499\n",
      "Test Accuracy Mean: 0.9321635251469212\n",
      "Test Accuracy STD: 0.00044987149065455986\n",
      "Test F1: 0.5265939444870608\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>Test_F1_score</th>\n",
       "      <th>CV_Accuracy</th>\n",
       "      <th>CV_Acc_STD</th>\n",
       "      <th>CV_F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Raw_token_NB</th>\n",
       "      <td>0.934414</td>\n",
       "      <td>0.564609</td>\n",
       "      <td>0.932161</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.548922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Token_NB</th>\n",
       "      <td>0.936925</td>\n",
       "      <td>0.553019</td>\n",
       "      <td>0.932164</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.526594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Test_Accuracy  Test_F1_score  CV_Accuracy  CV_Acc_STD  \\\n",
       "Raw_token_NB       0.934414       0.564609     0.932161    0.000523   \n",
       "Token_NB           0.936925       0.553019     0.932164    0.000450   \n",
       "\n",
       "              CV_F1_score  \n",
       "Raw_token_NB     0.548922  \n",
       "Token_NB         0.526594  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model_label = 'Token_NB'\n",
    "X_train_arg = X_train_t\n",
    "X_test_arg = X_test_t\n",
    "\n",
    "model_score(model, X_train_arg, X_test_arg, y_train, y_test, score_df, model_label)\n",
    "cv_score(model, X_train_arg, y_train, model_label)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 50 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_bi, X_test_bi=  vect_trans(CountVectorizer(ngram_range=(1,2)), X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.9739656652623391\n",
      "Test Accuracy: 0.9469300005206244\n",
      "Test F1 score: 0.393348503413268\n",
      "Test Accuracy Mean: 0.9441930363487323\n",
      "Test Accuracy STD: 0.00040737926477786937\n",
      "Test F1: 0.4762995403630869\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>Test_F1_score</th>\n",
       "      <th>CV_Accuracy</th>\n",
       "      <th>CV_Acc_STD</th>\n",
       "      <th>CV_F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Raw_token_NB</th>\n",
       "      <td>0.934414</td>\n",
       "      <td>0.564609</td>\n",
       "      <td>0.932161</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.548922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Token_NB</th>\n",
       "      <td>0.936925</td>\n",
       "      <td>0.553019</td>\n",
       "      <td>0.932164</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.526594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bigram_NB</th>\n",
       "      <td>0.946930</td>\n",
       "      <td>0.393349</td>\n",
       "      <td>0.944193</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.476300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Test_Accuracy  Test_F1_score  CV_Accuracy  CV_Acc_STD  \\\n",
       "Raw_token_NB       0.934414       0.564609     0.932161    0.000523   \n",
       "Token_NB           0.936925       0.553019     0.932164    0.000450   \n",
       "Bigram_NB          0.946930       0.393349     0.944193    0.000407   \n",
       "\n",
       "              CV_F1_score  \n",
       "Raw_token_NB     0.548922  \n",
       "Token_NB         0.526594  \n",
       "Bigram_NB        0.476300  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model_label = 'Bigram_NB'\n",
    "X_train_arg = X_train_bi\n",
    "X_test_arg = X_test_bi\n",
    "\n",
    "model_score(model, X_train_arg, X_test_arg, y_train, y_test, score_df, model_label)\n",
    "cv_score(model, X_train_arg, y_train, model_label)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# model = RandomForestClassifier(n_estimators= 100, max_depth=20, n_jobs=-1)\n",
    "# model_label = 'Bigram_RF'\n",
    "\n",
    "\n",
    "# model_score(model, X_train_bi, X_test_bi, y_train, y_test, score_df, model_label)\n",
    "# cv_score(model, X_train_bi, y_train, model_label)\n",
    "# score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tri-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_tri, X_test_tri=  vect_trans(CountVectorizer(ngram_range=(1,3), stop_words=stopwords), X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.9877683645521447\n",
      "Test Accuracy: 0.9445780033136211\n",
      "Test F1 score: 0.26895576651181574\n",
      "Test Accuracy Mean: 0.9444165985332346\n",
      "Test Accuracy STD: 0.00039801435185916374\n",
      "Test F1: 0.5027383149124014\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>Test_F1_score</th>\n",
       "      <th>CV_Accuracy</th>\n",
       "      <th>CV_Acc_STD</th>\n",
       "      <th>CV_F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Raw_token_NB</th>\n",
       "      <td>0.934414</td>\n",
       "      <td>0.564609</td>\n",
       "      <td>0.932161</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.548922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Token_NB</th>\n",
       "      <td>0.936925</td>\n",
       "      <td>0.553019</td>\n",
       "      <td>0.932164</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.526594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bigram_NB</th>\n",
       "      <td>0.946930</td>\n",
       "      <td>0.393349</td>\n",
       "      <td>0.944193</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.476300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trigram_NB</th>\n",
       "      <td>0.944578</td>\n",
       "      <td>0.268956</td>\n",
       "      <td>0.944417</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.502738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Test_Accuracy  Test_F1_score  CV_Accuracy  CV_Acc_STD  \\\n",
       "Raw_token_NB       0.934414       0.564609     0.932161    0.000523   \n",
       "Token_NB           0.936925       0.553019     0.932164    0.000450   \n",
       "Bigram_NB          0.946930       0.393349     0.944193    0.000407   \n",
       "Trigram_NB         0.944578       0.268956     0.944417    0.000398   \n",
       "\n",
       "              CV_F1_score  \n",
       "Raw_token_NB     0.548922  \n",
       "Token_NB         0.526594  \n",
       "Bigram_NB        0.476300  \n",
       "Trigram_NB       0.502738  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model_label = 'Trigram_NB'\n",
    "X_train_arg = X_train_tri\n",
    "X_test_arg = X_test_tri\n",
    "\n",
    "model_score(model, X_train_arg, X_test_arg, y_train, y_test, score_df, model_label)\n",
    "cv_score(model, X_train_arg, y_train, model_label)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# model = RandomForestClassifier(n_estimators= 100, max_depth=20, n_jobs=-1)\n",
    "# model_label = 'Trigram_RF'\n",
    "\n",
    "# model_score(model, X_train_tri, X_test_tri, y_train, y_test, score_df, model_label)\n",
    "# cv_score(model, X_train_tri, y_train, model_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch min/max df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {'CV__max_df':(1.0, 0.9),\n",
    "#        'CV__min_df': (1, 2, 0.01, 0.02),\n",
    "#         'CV__ngram_range':((1,1), (1,2), (1,3))}\n",
    "\n",
    "# gridcv(pipeCVNB, X_train, y_train, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# X_train_t, X_test_t=  vect_trans(CountVectorizer(max_df=1.0, min_df=1, ngram_range=(1,2), \n",
    "#                                                     stop_words=stopwords), X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = MultinomialNB()\n",
    "# model_label = 'Grid_DFNB'\n",
    "\n",
    "# model_score(model, X_train_t, X_test_t, y_train, y_test, score_df, model_label)\n",
    "# cv_score(model, X_train_t, y_train, model_label)\n",
    "# score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tf_t, X_test_tf_t = vect_trans(TfidfTransformer(), X_train_t, X_test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.9425709301126695\n",
      "Test Accuracy: 0.9411265699121982\n",
      "Test F1 score: 0.1277676950998185\n",
      "Test Accuracy Mean: 0.939962699105968\n",
      "Test Accuracy STD: 0.0001597900786319155\n",
      "Test F1: 0.09666475487668197\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>Test_F1_score</th>\n",
       "      <th>CV_Accuracy</th>\n",
       "      <th>CV_Acc_STD</th>\n",
       "      <th>CV_F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Raw_token_NB</th>\n",
       "      <td>0.934414</td>\n",
       "      <td>0.564609</td>\n",
       "      <td>0.932161</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.548922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Token_NB</th>\n",
       "      <td>0.936925</td>\n",
       "      <td>0.553019</td>\n",
       "      <td>0.932164</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.526594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bigram_NB</th>\n",
       "      <td>0.946930</td>\n",
       "      <td>0.393349</td>\n",
       "      <td>0.944193</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.476300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trigram_NB</th>\n",
       "      <td>0.944578</td>\n",
       "      <td>0.268956</td>\n",
       "      <td>0.944417</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.502738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf_t_NB</th>\n",
       "      <td>0.941127</td>\n",
       "      <td>0.127768</td>\n",
       "      <td>0.939963</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.096665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Test_Accuracy  Test_F1_score  CV_Accuracy  CV_Acc_STD  \\\n",
       "Raw_token_NB       0.934414       0.564609     0.932161    0.000523   \n",
       "Token_NB           0.936925       0.553019     0.932164    0.000450   \n",
       "Bigram_NB          0.946930       0.393349     0.944193    0.000407   \n",
       "Trigram_NB         0.944578       0.268956     0.944417    0.000398   \n",
       "Tfidf_t_NB         0.941127       0.127768     0.939963    0.000160   \n",
       "\n",
       "              CV_F1_score  \n",
       "Raw_token_NB     0.548922  \n",
       "Token_NB         0.526594  \n",
       "Bigram_NB        0.476300  \n",
       "Trigram_NB       0.502738  \n",
       "Tfidf_t_NB       0.096665  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model_label = 'Tfidf_t_NB'\n",
    "\n",
    "model_score(model, X_train_tf_t , X_test_tf_t, y_train, y_test, score_df, model_label)\n",
    "cv_score(model, X_train_tf_t, y_train, model_label)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.9425709301126695\n",
      "test score: 0.9411265699121982\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_tf_t, y_train)  \n",
    "test_score =  nb.score(X_test_tf_t, y_test)\n",
    "print('train score:', nb.score(X_train_tf_t, y_train))\n",
    "print('test score:', test_score)\n",
    "y_pred = nb.predict(X_test_tf_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1277676950998185\n",
      "0.5486514150832124\n",
      "0.9411265699121982\n",
      "0.9174536249200995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[305899,    429],\n",
       "       [ 18795,   1408]], dtype=int64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f1_score(y_test, y_pred) )\n",
    "print(f1_score(y_test, y_pred, average='macro') )\n",
    "print(f1_score(y_test, y_pred, average='micro') )\n",
    "print(f1_score(y_test, y_pred, average='weighted') )\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK Best Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreate text using ngrams\n",
    "def ngram_to_corpus(data, ngram_list, n):\n",
    "#     ngram_list = set({('let', 'us'), ('as', 'soon')})  # {('let', 'us'), ('as', 'soon')}\n",
    "#     tokens = ['please', 'let', 'us', 'know', 'as', 'soon', 'as', 'possible']\n",
    "    new_data = []\n",
    "    for text in data:\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        output = []\n",
    "        q_iter = iter(range(len(tokens)))\n",
    "        \n",
    "        for idx in q_iter:\n",
    "            output.append(tokens[idx])\n",
    "            if n == 2:\n",
    "                if idx < (len(tokens) - 1) and (tokens[idx], tokens[idx+1]) in ngram_list:\n",
    "                    output[-1] += '_' + tokens[idx+1]\n",
    "                    next(q_iter)\n",
    "            elif n == 3:\n",
    "                if idx < (len(tokens) - 2) and (tokens[idx], tokens[idx+1], tokens[idx+2] ) in ngram_list:\n",
    "                    output[-1] += '_' + tokens[idx+1] + '_' + tokens[idx+2]\n",
    "                    next(q_iter)\n",
    "                    next(q_iter)\n",
    "        new_data.append( ' '.join(output))\n",
    "\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create one list of all question tokens\n",
    "full_text = []\n",
    "\n",
    "for text in X_train:\n",
    "    full_text += [w for w in nltk.word_tokenize(text) if w not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6223102"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'would' in stopwords:\n",
    "    print(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('united', 'states'), ('best', 'way'), ('donald', 'trump'), ('year', 'old'), ('computer', 'science'), ('even', 'though'), ('high', 'school'), ('would', 'happen'), ('social', 'media'), ('north', 'korea'), ('pros', 'cons'), ('get', 'rid'), ('major', 'accomplishments'), ('jee', 'mains'), ('look', 'like'), ('would', 'win'), ('new', 'york'), ('machine', 'learning'), ('harry', 'potter'), ('years', 'old'), ('real', 'estate'), ('long', 'take'), ('saudi', 'arabia'), ('feel', 'like'), ('star', 'wars'), ('ssc', 'cgl'), ('mechanical', 'engineering'), ('elon', 'musk'), ('tv', 'show'), ('hillary', 'clinton'), ('hong', 'kong'), ('tamil', 'nadu'), ('president', 'trump'), ('useful', 'tips'), ('san', 'francisco'), ('different', 'types'), ('hotels', 'short-term'), ('artificial', 'intelligence'), ('prime', 'minister'), ('years', 'ago'), ('literary', 'devices'), ('tv', 'series'), ('credit', 'card'), ('narendra', 'modi'), ('many', 'people'), ('digital', 'marketing'), ('new', 'zealand'), ('los', 'angeles'), ('win', 'fight'), ('long', 'term'), ('someone', 'else'), ('get', 'job'), ('middle', 'east'), ('stock', 'market'), ('jee', 'advanced'), ('earn', 'money'), ('civil', 'engineering'), ('mental', 'illness'), ('lose', 'weight'), ('make', 'money'), ('vice', 'versa'), ('advantages', 'disadvantages'), ('real', 'life'), ('much', 'money'), ('black', 'hole'), ('chances', 'getting'), ('trump', 'supporters'), ('programming', 'language'), ('youtube', 'channel'), ('south', 'korea'), ('south', 'africa'), ('get', 'admission'), ('best', 'ways'), ('take', 'consideration'), ('global', 'warming'), ('west', 'bengal'), ('entrance', 'exam'), ('software', 'engineer'), ('silicon', 'valley'), ('game', 'thrones')]\n",
      "Wall time: 43.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create bigram vocabulary\n",
    "bigram_measures = collocations.BigramAssocMeasures()\n",
    "\n",
    "finder = nltk.BigramCollocationFinder.from_words(full_text)\n",
    "# scored = finder.score_ngrams( bigram_measures.likelihood_ratio  )\n",
    "bigram_vocab = finder.nbest(bigram_measures.likelihood_ratio, 80)\n",
    "print(bigram_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('jiu', 'jitsu'), ('muhoozi', 'kainerugaba'), ('neman', 'ashraf'), ('roald', 'dahl'), ('rudyard', 'kipling'), ('michio', 'kaku'), ('avada', 'kedavra'), ('aam', 'aadmi'), ('buenos', 'aires'), ('jaggi', 'vasudev'), ('disha', 'patani'), ('deng', 'xiaoping'), ('ronda', 'rousey'), ('abercrombie', 'fitch'), ('zaira', 'wasim'), ('endoplasmic', 'reticulum'), ('nathuram', 'godse'), ('sushma', 'swaraj'), ('jiang', 'zemin'), ('vande', 'mataram'), ('meryl', 'streep'), ('pakatan', 'harapan'), ('asim', 'qureshi'), ('sylvia', 'plath'), ('lata', 'mangeshkar'), ('dima', 'vorobiev'), ('kalpit', 'veerwal'), ('sindhu', 'satish'), ('pradhan', 'mantri'), ('aldous', 'huxley'), ('narsee', 'monjee'), ('ulcerative', 'colitis'), ('gauri', 'lankesh'), ('hadron', 'collider'), ('ballon', \"d'or\"), ('mitt', 'romney'), ('petyr', 'baelish'), ('shel', 'silverstein'), ('khaled', 'hosseini'), ('sourav', 'ganguly'), ('satoshi', 'nakamoto'), ('tubal', 'ligation'), ('satya', 'nadella'), ('agatha', 'christie'), ('klux', 'klan'), ('nigel', 'farage'), ('lingua', 'franca'), ('jules', 'verne'), ('jimi', 'hendrix'), ('smriti', 'irani'), ('raghuram', 'rajan'), ('shweta', 'shalini'), ('yoko', 'ono'), ('snoop', 'dogg'), ('winnie', 'pooh'), ('forrest', 'gump'), ('scarlett', 'johansson'), ('nicki', 'minaj'), ('magna', 'carta'), ('shinzo', 'abe'), ('hrithik', 'roshan'), ('stony', 'brook'), ('trinidad', 'tobago'), ('dushka', 'zapata'), ('nath', 'kovind'), ('rudy', 'giuliani'), ('kendriya', 'vidyalaya'), ('notre', 'dame'), ('des', 'moines'), ('hafiz', 'saeed'), ('barkha', 'dutt'), ('chester', 'bennington'), ('falun', 'gong'), ('che', 'guevara'), ('rabindranath', 'tagore'), ('vinay', 'kumaran'), ('arsene', 'wenger'), ('reza', 'pahlavi'), ('granth', 'sahib'), ('mustafa', 'kemal'), ('dawood', 'ibrahim'), ('ajit', 'pai'), ('sergey', 'brin'), ('ravindrababu', 'ravula'), ('tsar', 'bomba'), ('waldo', 'emerson'), ('kendrick', 'lamar'), ('mein', 'kampf'), ('elke', 'weiss'), ('sandeep', 'maheshwari'), ('looney', 'tunes'), ('lois', 'lowry'), ('ku', 'klux'), ('kellyanne', 'conway'), ('britney', 'spears'), ('milo', 'yiannopoulos'), ('magnus', 'carlsen'), ('mace', 'windu'), ('deathly', 'hallows'), ('alia', 'bhatt'), ('spongebob', 'squarepants'), ('kyrie', 'irving'), ('kj', 'somaiya'), ('acm', 'icpc'), ('tel', 'aviv'), ('lex', 'luthor'), ('hannibal', 'lecter'), ('nawaz', 'sharif'), ('boba', 'fett'), ('krav', 'maga'), ('aurora', 'borealis'), ('terence', 'tao'), ('zack', 'snyder'), ('bashar', 'al-assad'), ('dalai', 'lama'), ('brock', 'lesnar'), ('noam', 'chomsky'), ('zakir', 'naik'), ('fullmetal', 'alchemist'), ('hans', 'zimmer'), ('hugh', 'hefner'), ('muammar', 'gaddafi'), ('sundar', 'pichai'), ('stephenie', 'meyer'), ('ku', 'leuven'), ('berkshire', 'hathaway'), ('chiang', 'mai'), ('fidel', 'castro'), ('kung', 'fu'), ('travis', 'kalanick'), ('subramanian', 'swamy'), ('miley', 'cyrus'), ('burj', 'khalifa'), ('shashi', 'tharoor'), ('catcher', 'rye'), ('oprah', 'winfrey'), ('karni', 'sena'), ('paulo', 'coelho'), ('ralph', 'waldo'), ('kurt', 'cobain'), ('peyton', 'manning'), ('bosnia', 'herzegovina'), ('moderated', 'caucus'), ('otto', 'warmbier'), ('ariana', 'grande'), ('dhinchak', 'pooja'), ('shin', 'splints'), ('coca', 'cola'), ('mitch', 'mcconnell'), ('ivan', 'tregear'), ('truman', 'capote'), ('selena', 'gomez'), ('solitary', 'confinement'), ('monte', 'carlo'), ('andaman', 'nicobar'), ('majin', 'buu'), ('bunsen', 'burner'), ('consiglio', 'devastations'), ('habib', 'fanny'), ('kulbhushan', 'jadhav'), ('tipu', 'sultan'), ('brad', 'pitt'), ('netaji', 'subhash'), ('jill', 'stein'), ('aishwarya', 'rai'), ('ping', 'pong'), ('dennis', 'rodman'), ('julian', 'assange'), ('euron', 'greyjoy'), ('martian', 'manhunter'), ('deepika', 'padukone'), ('conor', 'mcgregor'), ('babe', 'ruth'), ('dy', 'patil'), ('katrina', 'kaif'), ('amitabh', 'bachchan'), ('arnab', 'goswami'), ('nova', 'scotia'), ('arun', 'jaitley'), ('maya', 'angelou'), ('en', 'masse'), ('pawan', 'kalyan'), ('nikki', 'haley'), ('sergei', 'skripal'), ('marilyn', 'monroe'), ('palo', 'alto'), ('bharati', 'vidyapeeth'), ('sigmund', 'freud'), ('ayn', 'rand'), ('dunkin', 'donuts'), ('millia', 'islamia'), ('déjà', 'vu'), ('buzz', 'aldrin'), ('degrasse', 'tyson'), ('inguinal', 'hernia'), ('ellen', 'degeneres'), ('rachel', 'maddow'), ('deja', 'vu'), ('alfie', 'evans'), ('são', 'paulo')]\n",
      "Wall time: 15.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create bigram vocabulary\n",
    "bigram_measures = collocations.BigramAssocMeasures()\n",
    "\n",
    "\n",
    "finder3 = nltk.BigramCollocationFinder.from_words(full_text)\n",
    "finder3.apply_freq_filter(10)\n",
    "finder3.apply_word_filter(lambda x: x in stopwords)\n",
    "best_pmi = finder3.nbest(bigram_measures.pmi, 200)\n",
    "print(best_pmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('united', 'states', 'america'), ('president', 'united', 'states'), ('united', 'states', 'india'), ('states', 'united', 'states'), ('history', 'united', 'states'), ('united', 'states', 'constitution'), ('united', 'states', 'government'), ('united', 'states', 'matter'), ('united', 'states', 'like'), ('united', 'states', 'army'), ('united', 'states', 'us'), ('united', 'states', 'usa'), ('united', 'states', 'united'), ('south', 'united', 'states'), ('coast', 'united', 'states'), ('canada', 'united', 'states'), ('united', 'states', 'military'), ('united', 'states', 'marine'), ('outside', 'united', 'states'), ('happen', 'united', 'states')]\n",
      "Wall time: 7min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create trigram vocabulary\n",
    "trigram_measures = collocations.TrigramAssocMeasures()\n",
    "finder = nltk.TrigramCollocationFinder.from_words(full_text)\n",
    "trigram_vocab = finder.nbest(trigram_measures.likelihood_ratio, 20)\n",
    "print(trigram_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create text with bigram replacement\n",
    "train['bigram_question_lkhd'] = ngram_to_corpus(clean_questions, bigram_vocab, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create text with both tri and bigram in text, by applying trigram first\n",
    "train['trigram_question_lkhd'] = ngram_to_corpus(clean_questions, trigram_vocab, 3)\n",
    "train['trigram_question_lkhd'] = ngram_to_corpus(train['trigram_question_lkhd'], bigram_vocab, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['know whether girl done sex sex',\n",
       "       'become fast learner professional career personal life',\n",
       "       'united_states become largest dictatorship world',\n",
       "       'strangest phenomenon know witnessed generated area electronics explanation terms modern physics',\n",
       "       'leave friends find new ones'], dtype=object)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['trigram_question_lkhd'][20:25].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[['bigram_question_lkhd','trigram_question_lkhd']]\n",
    "y = train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=495, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1044897"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram_question_lkhd</th>\n",
       "      <th>trigram_question_lkhd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1077331</th>\n",
       "      <td>procedure officially changing name india</td>\n",
       "      <td>procedure officially changing name india</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334276</th>\n",
       "      <td>ancient egypt polytheism</td>\n",
       "      <td>ancient egypt polytheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620299</th>\n",
       "      <td>whenever put blood pressure monitor get scared...</td>\n",
       "      <td>whenever put blood pressure monitor get scared...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098236</th>\n",
       "      <td>ego react suicide</td>\n",
       "      <td>ego react suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548923</th>\n",
       "      <td>join tcs fresher missed campus hiring</td>\n",
       "      <td>join tcs fresher missed campus hiring</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      bigram_question_lkhd  \\\n",
       "1077331           procedure officially changing name india   \n",
       "334276                            ancient egypt polytheism   \n",
       "620299   whenever put blood pressure monitor get scared...   \n",
       "1098236                                  ego react suicide   \n",
       "548923               join tcs fresher missed campus hiring   \n",
       "\n",
       "                                     trigram_question_lkhd  \n",
       "1077331           procedure officially changing name india  \n",
       "334276                            ancient egypt polytheism  \n",
       "620299   whenever put blood pressure monitor get scared...  \n",
       "1098236                                  ego react suicide  \n",
       "548923               join tcs fresher missed campus hiring  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model using bigram text\n",
    "X_train_bi, X_test_bi =  vect_trans(CountVectorizer(max_df=1.0,  min_df=1, ngram_range=(1,1), stop_words=stopwords),\n",
    "                                   X_train.bigram_question_lkhd, X_test.bigram_question_lkhd,)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.938080978316523\n",
      "Test Accuracy: 0.9373030912049\n",
      "Test F1 score: 0.5532216705766818\n",
      "Test Accuracy Mean: 0.9328144311909551\n",
      "Test Accuracy STD: 0.00045544676447581347\n",
      "Test F1: 0.5289402582650158\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>Test_F1_score</th>\n",
       "      <th>CV_Accuracy</th>\n",
       "      <th>CV_Acc_STD</th>\n",
       "      <th>CV_F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Raw_token_NB</th>\n",
       "      <td>0.934414</td>\n",
       "      <td>0.564609</td>\n",
       "      <td>0.932161</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.548922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Token_NB</th>\n",
       "      <td>0.936925</td>\n",
       "      <td>0.553019</td>\n",
       "      <td>0.932164</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.526594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bigram_NB</th>\n",
       "      <td>0.946930</td>\n",
       "      <td>0.393349</td>\n",
       "      <td>0.944193</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.476300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trigram_NB</th>\n",
       "      <td>0.944578</td>\n",
       "      <td>0.268956</td>\n",
       "      <td>0.944417</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.502738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf_t_NB</th>\n",
       "      <td>0.941127</td>\n",
       "      <td>0.127768</td>\n",
       "      <td>0.939963</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.096665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bigram_best_NB</th>\n",
       "      <td>0.937303</td>\n",
       "      <td>0.553222</td>\n",
       "      <td>0.932814</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.528940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Test_Accuracy  Test_F1_score  CV_Accuracy  CV_Acc_STD  \\\n",
       "Raw_token_NB         0.934414       0.564609     0.932161    0.000523   \n",
       "Token_NB             0.936925       0.553019     0.932164    0.000450   \n",
       "Bigram_NB            0.946930       0.393349     0.944193    0.000407   \n",
       "Trigram_NB           0.944578       0.268956     0.944417    0.000398   \n",
       "Tfidf_t_NB           0.941127       0.127768     0.939963    0.000160   \n",
       "Bigram_best_NB       0.937303       0.553222     0.932814    0.000455   \n",
       "\n",
       "                CV_F1_score  \n",
       "Raw_token_NB       0.548922  \n",
       "Token_NB           0.526594  \n",
       "Bigram_NB          0.476300  \n",
       "Trigram_NB         0.502738  \n",
       "Tfidf_t_NB         0.096665  \n",
       "Bigram_best_NB     0.528940  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model_label = 'Bigram_best_NB'\n",
    "\n",
    "model_score(model, X_train_bi, X_test_bi, y_train, y_test, score_df, model_label)\n",
    "cv_score(model, X_train_bi, y_train, model_label)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model using bigram text\n",
    "X_train_tri, X_test_tri =  vect_trans(CountVectorizer(max_df=1.0,  min_df=1, ngram_range=(1,1), stop_words=stopwords),\n",
    "                                   X_train.trigram_question_lkhd, X_test.trigram_question_lkhd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.9380943767663225\n",
      "Test Accuracy: 0.9373069193224232\n",
      "Test F1 score: 0.5531880064387635\n",
      "Test Accuracy Mean: 0.9328211303966206\n",
      "Test Accuracy STD: 0.00045313500457456573\n",
      "Test F1: 0.5289273823841426\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>Test_F1_score</th>\n",
       "      <th>CV_Accuracy</th>\n",
       "      <th>CV_Acc_STD</th>\n",
       "      <th>CV_F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Raw_token_NB</th>\n",
       "      <td>0.934414</td>\n",
       "      <td>0.564609</td>\n",
       "      <td>0.932161</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.548922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Token_NB</th>\n",
       "      <td>0.936925</td>\n",
       "      <td>0.553019</td>\n",
       "      <td>0.932164</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.526594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bigram_NB</th>\n",
       "      <td>0.946930</td>\n",
       "      <td>0.393349</td>\n",
       "      <td>0.944193</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.476300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trigram_NB</th>\n",
       "      <td>0.944578</td>\n",
       "      <td>0.268956</td>\n",
       "      <td>0.944417</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.502738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf_t_NB</th>\n",
       "      <td>0.941127</td>\n",
       "      <td>0.127768</td>\n",
       "      <td>0.939963</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.096665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bigram_best_NB</th>\n",
       "      <td>0.937303</td>\n",
       "      <td>0.553222</td>\n",
       "      <td>0.932814</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.528940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trigram_best_NB</th>\n",
       "      <td>0.937307</td>\n",
       "      <td>0.553188</td>\n",
       "      <td>0.932821</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.528927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Test_Accuracy  Test_F1_score  CV_Accuracy  CV_Acc_STD  \\\n",
       "Raw_token_NB          0.934414       0.564609     0.932161    0.000523   \n",
       "Token_NB              0.936925       0.553019     0.932164    0.000450   \n",
       "Bigram_NB             0.946930       0.393349     0.944193    0.000407   \n",
       "Trigram_NB            0.944578       0.268956     0.944417    0.000398   \n",
       "Tfidf_t_NB            0.941127       0.127768     0.939963    0.000160   \n",
       "Bigram_best_NB        0.937303       0.553222     0.932814    0.000455   \n",
       "Trigram_best_NB       0.937307       0.553188     0.932821    0.000453   \n",
       "\n",
       "                 CV_F1_score  \n",
       "Raw_token_NB        0.548922  \n",
       "Token_NB            0.526594  \n",
       "Bigram_NB           0.476300  \n",
       "Trigram_NB          0.502738  \n",
       "Tfidf_t_NB          0.096665  \n",
       "Bigram_best_NB      0.528940  \n",
       "Trigram_best_NB     0.528927  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model_label = 'Trigram_best_NB'\n",
    "\n",
    "model_score(model, X_train_tri, X_test_tri, y_train, y_test, score_df, model_label)\n",
    "cv_score(model, X_train_tri, y_train, model_label)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regenerate bi/trigrams after replacing previous ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "full_text_ngrams = []\n",
    "\n",
    "for text in X_train.trigram_question_lkhd:\n",
    "    full_text_ngrams += [w for w in nltk.word_tokenize(text) if w not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('would_win', 'fight'), ('useful_tips', 'someone'), ('hotels_short-term', 'business'), ('many', 'times'), ('bad', 'neighborhoods'), ('business', 'travelers'), ('world', 'war'), ('much', 'cost'), ('advice', 'would'), ('good', 'idea'), ('supreme', 'court'), ('civil', 'war'), ('bits', 'pilani'), ('video', 'games'), ('las', 'vegas'), ('th', 'century'), ('mechanical', 'engineer'), ('bank', 'account'), ('best', 'friend'), ('personality', 'disorder'), ('data', 'science'), ('gordon', 'miller'), ('much', 'time'), ('first', 'time'), ('mutual', 'funds'), ('would', 'recommend'), ('good', 'hotels_short-term'), ('soviet', 'union'), ('best', 'place'), ('lesser', 'known'), ('electrical', 'engineering'), ('questions', 'asked'), ('sri', 'lanka'), ('someone', 'starting'), ('starting', 'work'), (\"'ve\", 'ever'), ('mental', 'health'), ('acting', 'style'), ('twin', 'flame'), ('rahul', 'gandhi')]\n",
      "Wall time: 44.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create bigram vocabulary\n",
    "bigram_measures = collocations.BigramAssocMeasures()\n",
    "\n",
    "finder = nltk.BigramCollocationFinder.from_words(full_text_ngrams)\n",
    "# scored = finder.score_ngrams( bigram_measures.likelihood_ratio  )\n",
    "bigram_vocab = finder.nbest(bigram_measures.likelihood_ratio, 40)\n",
    "print(bigram_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('kim', 'jong', 'un'), ('controversial', 'events', 'mentioned'), ('borderline', 'personality', 'disorder'), ('hotels_short-term', 'business', 'travelers'), ('take_consideration', 'writing', 'biography'), ('rbi', 'grade', 'b'), ('avengers', 'infinity', 'war'), ('lesser', 'known', 'facts'), ('manufacturing', 'process', 'improved'), ('fifa', 'world', 'cup'), ('tips', 'write', 'summary'), ('characters', 'change', 'throughout'), ('useful_tips', 'someone', 'starting'), ('student', 'organizations', 'join'), ('writing', 'style', 'structure'), ('useful_tips', 'students', 'starting'), ('starting', 'first', 'semester'), ('download', 'test', 'bank'), ('things', 'weekends', 'student'), ('world', 'war', 'ii')]\n",
      "Wall time: 30.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create trigram vocabulary\n",
    "trigram_measures = collocations.TrigramAssocMeasures()\n",
    "finder = nltk.TrigramCollocationFinder.from_words(full_text_ngrams)\n",
    "finder.apply_freq_filter(100)\n",
    "trigram_vocab = finder.nbest(trigram_measures.pmi, 20)\n",
    "print(trigram_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create text with bigram replacement\n",
    "train['bigram_question_2'] = ngram_to_corpus(clean_questions, bigram_vocab, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create text with both tri and bigram in text, by applying trigram first\n",
    "train['trigram_question_2'] = ngram_to_corpus(clean_questions, trigram_vocab, 3)\n",
    "train['trigram_question_2'] = ngram_to_corpus(train['trigram_question_2'], bigram_vocab, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[['bigram_question_2','trigram_question_2']]\n",
    "y = train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=495, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1044897"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model using bigram text\n",
    "X_train_bi, X_test_bi =  vect_trans(CountVectorizer(max_df=1.0,  min_df=1, ngram_range=(1,1), stop_words=stopwords),\n",
    "                                   X_train.bigram_question_2, X_test.bigram_question_2,)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.9374627355614955\n",
      "Test Accuracy: 0.9365144989951192\n",
      "Test F1 score: 0.5515898767034393\n",
      "Test Accuracy Mean: 0.9322583954308508\n",
      "Test Accuracy STD: 0.00044042110104467624\n",
      "Test F1: 0.5289119949539701\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>Test_F1_score</th>\n",
       "      <th>CV_Accuracy</th>\n",
       "      <th>CV_Acc_STD</th>\n",
       "      <th>CV_F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Raw_token_NB</th>\n",
       "      <td>0.934414</td>\n",
       "      <td>0.564609</td>\n",
       "      <td>0.932161</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.548922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Token_NB</th>\n",
       "      <td>0.936925</td>\n",
       "      <td>0.553019</td>\n",
       "      <td>0.932164</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.526594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bigram_NB</th>\n",
       "      <td>0.946930</td>\n",
       "      <td>0.393349</td>\n",
       "      <td>0.944193</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.476300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trigram_NB</th>\n",
       "      <td>0.944578</td>\n",
       "      <td>0.268956</td>\n",
       "      <td>0.944417</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.502738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf_t_NB</th>\n",
       "      <td>0.941127</td>\n",
       "      <td>0.127768</td>\n",
       "      <td>0.939963</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.096665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bigram_best_NB</th>\n",
       "      <td>0.937303</td>\n",
       "      <td>0.553222</td>\n",
       "      <td>0.932814</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.528940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trigram_best_NB</th>\n",
       "      <td>0.937307</td>\n",
       "      <td>0.553188</td>\n",
       "      <td>0.932821</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.528927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bigram_best_NB2</th>\n",
       "      <td>0.936514</td>\n",
       "      <td>0.551590</td>\n",
       "      <td>0.932258</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>0.528912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Test_Accuracy  Test_F1_score  CV_Accuracy  CV_Acc_STD  \\\n",
       "Raw_token_NB          0.934414       0.564609     0.932161    0.000523   \n",
       "Token_NB              0.936925       0.553019     0.932164    0.000450   \n",
       "Bigram_NB             0.946930       0.393349     0.944193    0.000407   \n",
       "Trigram_NB            0.944578       0.268956     0.944417    0.000398   \n",
       "Tfidf_t_NB            0.941127       0.127768     0.939963    0.000160   \n",
       "Bigram_best_NB        0.937303       0.553222     0.932814    0.000455   \n",
       "Trigram_best_NB       0.937307       0.553188     0.932821    0.000453   \n",
       "Bigram_best_NB2       0.936514       0.551590     0.932258    0.000440   \n",
       "\n",
       "                 CV_F1_score  \n",
       "Raw_token_NB        0.548922  \n",
       "Token_NB            0.526594  \n",
       "Bigram_NB           0.476300  \n",
       "Trigram_NB          0.502738  \n",
       "Tfidf_t_NB          0.096665  \n",
       "Bigram_best_NB      0.528940  \n",
       "Trigram_best_NB     0.528927  \n",
       "Bigram_best_NB2     0.528912  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model_label = 'Bigram_best_NB2'\n",
    "\n",
    "model_score(model, X_train_bi, X_test_bi, y_train, y_test, score_df, model_label)\n",
    "cv_score(model, X_train_bi, y_train, model_label)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model using bigram text\n",
    "X_train_tri, X_test_tri =  vect_trans(CountVectorizer(max_df=1.0,  min_df=1, ngram_range=(1,1), stop_words=stopwords),\n",
    "                                   X_train.trigram_question_2, X_test.trigram_question_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.9374895324610942\n",
      "Test Accuracy: 0.936529811465212\n",
      "Test F1 score: 0.5515525262360705\n",
      "Test Accuracy Mean: 0.9322995477858168\n",
      "Test Accuracy STD: 0.0004353257097245323\n",
      "Test F1: 0.5290324660119806\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>Test_F1_score</th>\n",
       "      <th>CV_Accuracy</th>\n",
       "      <th>CV_Acc_STD</th>\n",
       "      <th>CV_F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Raw_token_NB</th>\n",
       "      <td>0.934414</td>\n",
       "      <td>0.564609</td>\n",
       "      <td>0.932161</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.548922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Token_NB</th>\n",
       "      <td>0.936925</td>\n",
       "      <td>0.553019</td>\n",
       "      <td>0.932164</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.526594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bigram_NB</th>\n",
       "      <td>0.946930</td>\n",
       "      <td>0.393349</td>\n",
       "      <td>0.944193</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.476300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trigram_NB</th>\n",
       "      <td>0.944578</td>\n",
       "      <td>0.268956</td>\n",
       "      <td>0.944417</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.502738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf_t_NB</th>\n",
       "      <td>0.941127</td>\n",
       "      <td>0.127768</td>\n",
       "      <td>0.939963</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.096665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bigram_best_NB</th>\n",
       "      <td>0.937303</td>\n",
       "      <td>0.553222</td>\n",
       "      <td>0.932814</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.528940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trigram_best_NB</th>\n",
       "      <td>0.937307</td>\n",
       "      <td>0.553188</td>\n",
       "      <td>0.932821</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.528927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bigram_best_NB2</th>\n",
       "      <td>0.936514</td>\n",
       "      <td>0.551590</td>\n",
       "      <td>0.932258</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>0.528912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trigram_best_NB2</th>\n",
       "      <td>0.936530</td>\n",
       "      <td>0.551553</td>\n",
       "      <td>0.932300</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.529032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Test_Accuracy  Test_F1_score  CV_Accuracy  CV_Acc_STD  \\\n",
       "Raw_token_NB           0.934414       0.564609     0.932161    0.000523   \n",
       "Token_NB               0.936925       0.553019     0.932164    0.000450   \n",
       "Bigram_NB              0.946930       0.393349     0.944193    0.000407   \n",
       "Trigram_NB             0.944578       0.268956     0.944417    0.000398   \n",
       "Tfidf_t_NB             0.941127       0.127768     0.939963    0.000160   \n",
       "Bigram_best_NB         0.937303       0.553222     0.932814    0.000455   \n",
       "Trigram_best_NB        0.937307       0.553188     0.932821    0.000453   \n",
       "Bigram_best_NB2        0.936514       0.551590     0.932258    0.000440   \n",
       "Trigram_best_NB2       0.936530       0.551553     0.932300    0.000435   \n",
       "\n",
       "                  CV_F1_score  \n",
       "Raw_token_NB         0.548922  \n",
       "Token_NB             0.526594  \n",
       "Bigram_NB            0.476300  \n",
       "Trigram_NB           0.502738  \n",
       "Tfidf_t_NB           0.096665  \n",
       "Bigram_best_NB       0.528940  \n",
       "Trigram_best_NB      0.528927  \n",
       "Bigram_best_NB2      0.528912  \n",
       "Trigram_best_NB2     0.529032  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model_label = 'Trigram_best_NB2'\n",
    "\n",
    "model_score(model, X_train_tri, X_test_tri, y_train, y_test, score_df, model_label)\n",
    "cv_score(model, X_train_tri, y_train, model_label)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
