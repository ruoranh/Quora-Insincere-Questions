{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text manipulation\n",
    "import re\n",
    "import string\n",
    "\n",
    "# Data management\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import *\n",
    "import scipy\n",
    "\n",
    "# NLP\n",
    "import nltk\n",
    "import nltk.collocations as collocations\n",
    "from nltk.tag import tnt\n",
    "import spacy\n",
    "\n",
    "# modelling\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.cluster import MeanShift\n",
    "\n",
    "#visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, clear_output\n",
    "import matplotlib.style as style \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of insincere questions: 80810\n",
      "No. of sincere questions: 1225312\n",
      "% of insincere questions: 0.06187017751787352\n",
      "Null score: 0.9381298224821265\n"
     ]
    }
   ],
   "source": [
    "no_insincere = train[train['target']==1].target.count()\n",
    "no_sincere = train[train['target']==0].target.count()\n",
    "\n",
    "print('No. of insincere questions:', no_insincere)\n",
    "print('No. of sincere questions:', no_sincere)\n",
    "print('% of insincere questions:', train.target.mean())\n",
    "print('Null score:', 1- train.target.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions and pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vect_trans(vectorizer, X_train, X_test):\n",
    "    # can also take a transformer\n",
    "    vect = vectorizer\n",
    "    vect.fit(X_train)\n",
    "    return vect.transform(X_train), vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultinominalNB function for printing scores and storing into df.\n",
    "def model_score(model, X_train, X_test, y_train, y_test, score_df, model_label):\n",
    "    estimator = model\n",
    "    estimator.fit(X_train, y_train)\n",
    "    test_score =  estimator.score(X_test, y_test)\n",
    "    f1 = f1_score(y_test, estimator.predict(X_test))\n",
    "    \n",
    "    print('Train Accuracy :', estimator.score(X_train, y_train))\n",
    "    print('Test Accuracy:', test_score)\n",
    "    print('Test F1 score:', f1)\n",
    "    score_df.loc[model_label, 'Test_Accuracy'] = test_score\n",
    "    score_df.loc[model_label, 'Test_F1_score'] = f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validate function for printing scores and storing into df.\n",
    "def cv_score(model, X, y, model_label,  cv=5, ):    \n",
    "    \n",
    "    # instantiating model\n",
    "    estimator = model\n",
    "    \n",
    "    cv_result = cross_validate(estimator, X, y, cv = cv, n_jobs=-1, scoring=['accuracy', 'f1'])\n",
    "    \n",
    "    print('Test Accuracy Mean:',cv_result['test_accuracy'].mean())\n",
    "    print('Test Accuracy STD:',cv_result['test_accuracy'].std())\n",
    "    print('Test F1:', cv_result['test_f1'].mean())\n",
    "    score_df.loc[model_label, 'CV_Accuracy'] = cv_result['test_accuracy'].mean()\n",
    "    score_df.loc[model_label, 'CV_Acc_STD'] = cv_result['test_accuracy'].std()\n",
    "    score_df.loc[model_label, 'CV_F1_score'] = cv_result['test_f1'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV function, auto display best score and parameters and storing in df\n",
    "def gridcv(model, X, y, params, cv= 5 ):\n",
    "    \n",
    "    # instantiating model can also be a pipeline\n",
    "    estimator = model\n",
    "    \n",
    "    gridcv = GridSearchCV(estimator=estimator, param_grid=params, cv = cv, verbose=10, n_jobs=6)\n",
    "    gridcv.fit(X, y)\n",
    "    \n",
    "    print(gridcv.best_params_)\n",
    "    print(gridcv.best_score_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer pipeline and parameters\n",
    "pipeCVNB = Pipeline([('CV',CountVectorizer(stop_words=stopwords)), \n",
    "                    ('NB',MultinomialNB())])\n",
    "\n",
    "paramsCVNB = {'CV__max_df':(1.0, 0.9, 0.8, 0.7),\n",
    "       'CV__min_df': (1, 2, 0.01 , 0.1, 0.2),\n",
    "         'CV__ngram_range':((1,1), (1,2), (1,3))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TfidfVectorizer pipeline and parameters\n",
    "pipeTVNB = Pipeline([('TV',TfidfVectorizer(stop_words=stopwords)), \n",
    "                    ('NB',MultinomialNB())])\n",
    "\n",
    "paramsTVNB = {'TV__max_df':(1.0, 0.9, 0.8, 0.7, 0.6),\n",
    "       'TV__min_df': (1, 2, 0.01, 0.05, 0.1),\n",
    "         'TV__ngram_range':((1,1), (1,2), (1,3), (2,2), (2,3))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 48 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clean_questions = (re.sub(\"[^A-Za-z']+\", ' ', q).lower() for q in train['question_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# using spaCy to lemmatize using POS tags in one step, with out converting between WordNet and Treebank tags, using NLTK\n",
    "spac = spacy.load('en', disable=['parser', 'ner'])\n",
    "def lemmatizer(text):\n",
    "    text = spac(text)\n",
    "    return ' '.join([token.lemma_ for token in text if token.lemma_ not in stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 7min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lemma_q = [lemmatizer(q) for q in train.question_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>quebec nationalist see -PRON- province nation ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-PRON- adopt dog would -PRON- encourage people...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>velocity affect time velocity affect space geo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>otto von guericke use magdeburg hemisphere</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-PRON- convert montra helicon mountain bike ch...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       question_text  target\n",
       "0  quebec nationalist see -PRON- province nation ...       0\n",
       "1  -PRON- adopt dog would -PRON- encourage people...       0\n",
       "2  velocity affect time velocity affect space geo...       0\n",
       "3         otto von guericke use magdeburg hemisphere       0\n",
       "4  -PRON- convert montra helicon mountain bike ch...       0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma_train = pd.DataFrame(lemma_q, columns = ['question_text'])\n",
    "lemma_train['target'] = train.target\n",
    "lemma_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemma_train.to_pickle('./lemma_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_train = pd.read_pickle('./lemma_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = list(nltk.corpus.stopwords.words('english')) + list(string.punctuation) + [\"''\", '``','’','“','”', \"'s\", \"'d\", \"'ll\", \"'t\", \"n't\", \"ca\", 'wo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# remove stop words and lower all characters\n",
    "clean_questions = [' '.join(w for w in nltk.word_tokenize(q.lower()) if w not in stopwords) for q in clean_questions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing all identity labels each question with a common labels\n",
    "def labels_to_question(data, label_list, label_type):\n",
    "         \n",
    "    new_data = []\n",
    "    \n",
    "    # For every questions\n",
    "    i_data = 0\n",
    "    for i_data in range(len(data)):\n",
    "        question = data[i_data].lower()\n",
    "        output = []\n",
    "        \n",
    "        # compare each label to question\n",
    "        for label in label_list:\n",
    "\n",
    "            if label in question:\n",
    "\n",
    "                que_t = nltk.word_tokenize(question)\n",
    "                lab_t = nltk.word_tokenize(label)\n",
    "\n",
    "                i_que = 0\n",
    "                while i_que < len(que_t):\n",
    "                    i_lab = 0\n",
    "                    \n",
    "                    # If current token is same as first label token, continue compare rest of the tokens. \n",
    "                    if que_t[i_que] == lab_t[0]:\n",
    "                        que_t[i_que] = label_type\n",
    "                        i_lab += 1\n",
    "                        i_que += 1\n",
    "\n",
    "                        # Remove trailing question tokens if they match trailing label tokens\n",
    "                        try: \n",
    "                            while i_lab < len(lab_t):\n",
    "                                if que_t[i_que] == lab_t[i_lab]:\n",
    "                                    que_t.pop(i_que)\n",
    "                                    i_lab += 1\n",
    "                                else:\n",
    "                                    break\n",
    "    #                     elif que_t[i_que] == lab_t[0]:\n",
    "    #                         print('Question: ',question, i_data)\n",
    "    #                         print('label: ', label)\n",
    "                        except:\n",
    "                            pass\n",
    "                    i_que += 1\n",
    "                question = ' '.join(que_t)\n",
    "#                 print('after: ', question)\n",
    "#                 print('label: ', label)\n",
    "        new_data.append(question)                   \n",
    "        if i_data % 1000 == 0:\n",
    "            clear_output(wait=True)\n",
    "            print(label_type, i_data)\n",
    "    return new_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identity groupd filters, created from online lists, most frequent insincere words and manual editing.\n",
    "ID_filter = pd.read_csv('ID_filter.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RELIGIOUS_ID</th>\n",
       "      <th>RACIAL_ID</th>\n",
       "      <th>NATIONAL_ID</th>\n",
       "      <th>NATIONALITY_ID</th>\n",
       "      <th>GENDER_ID</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Political_groups</th>\n",
       "      <th>Political_figure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>buddhist</td>\n",
       "      <td>white people</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Afghans</td>\n",
       "      <td>girls</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trump supporters</td>\n",
       "      <td>donald trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>catholic</td>\n",
       "      <td>black people</td>\n",
       "      <td>Albania</td>\n",
       "      <td>Albanians</td>\n",
       "      <td>boys</td>\n",
       "      <td>NaN</td>\n",
       "      <td>democrate</td>\n",
       "      <td>president trump</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  RELIGIOUS_ID     RACIAL_ID  NATIONAL_ID NATIONALITY_ID GENDER_ID  \\\n",
       "0     buddhist  white people  Afghanistan        Afghans     girls   \n",
       "1     catholic  black people      Albania      Albanians      boys   \n",
       "\n",
       "   Unnamed: 5  Political_groups Political_figure  \n",
       "0         NaN  trump supporters     donald trump  \n",
       "1         NaN         democrate  president trump  "
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID_filter.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "religious_ID = ID_filter.RELIGIOUS_ID.dropna()\n",
    "racial_ID = ID_filter.RACIAL_ID.dropna()\n",
    "national_ID = ID_filter.NATIONAL_ID.dropna()\n",
    "nationality_ID = ID_filter.NATIONALITY_ID.dropna()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NATIONALITY_ID 1306000\n",
      "Wall time: 3min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clean_questions = labels_to_question(clean_questions, religious_ID, 'RELIGIOUS_ID')\n",
    "clean_questions = labels_to_question(clean_questions, racial_ID, 'RACIAL_ID')\n",
    "clean_questions = labels_to_question(clean_questions, national_ID, 'NATIONAL_ID')\n",
    "clean_questions = labels_to_question(clean_questions, nationality_ID, 'NATIONALITY_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = clean_questions\n",
    "y = lemma_train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state = 495)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Default count vectorizer on raw text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 35.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(train.question_text, train.target,\n",
    "                                                                    stratify=train.target, random_state = 495)\n",
    "\n",
    "X_train_raw_t, X_test_raw_t=  vect_trans(CountVectorizer(), X_train_raw, X_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.9350739237089765\n",
      "Test Accuracy: 0.9344135778838762\n",
      "Test F1 score: 0.5646092542896641\n",
      "Test Accuracy Mean: 0.9321614838567932\n",
      "Test Accuracy STD: 0.0005228593021778298\n",
      "Test F1: 0.5489215714930169\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>Test_F1_score</th>\n",
       "      <th>CV_Accuracy</th>\n",
       "      <th>CV_Acc_STD</th>\n",
       "      <th>CV_F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Raw_token_NB</th>\n",
       "      <td>0.934414</td>\n",
       "      <td>0.564609</td>\n",
       "      <td>0.932161</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.548922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Token_NB</th>\n",
       "      <td>0.937219</td>\n",
       "      <td>0.556143</td>\n",
       "      <td>0.932638</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.530513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bigram_NB</th>\n",
       "      <td>0.947245</td>\n",
       "      <td>0.396637</td>\n",
       "      <td>0.944612</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.481289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trigram_NB</th>\n",
       "      <td>0.944777</td>\n",
       "      <td>0.271846</td>\n",
       "      <td>0.944942</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.508322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf_t_NB</th>\n",
       "      <td>0.941736</td>\n",
       "      <td>0.147893</td>\n",
       "      <td>0.940431</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.112072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bigram_best_NB</th>\n",
       "      <td>0.937383</td>\n",
       "      <td>0.555746</td>\n",
       "      <td>0.933297</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.533363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trigram_best_NB</th>\n",
       "      <td>0.937387</td>\n",
       "      <td>0.555688</td>\n",
       "      <td>0.933304</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.533348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Test_Accuracy  Test_F1_score  CV_Accuracy  CV_Acc_STD  \\\n",
       "Raw_token_NB          0.934414       0.564609     0.932161    0.000523   \n",
       "Token_NB              0.937219       0.556143     0.932638    0.000459   \n",
       "Bigram_NB             0.947245       0.396637     0.944612    0.000376   \n",
       "Trigram_NB            0.944777       0.271846     0.944942    0.000415   \n",
       "Tfidf_t_NB            0.941736       0.147893     0.940431    0.000149   \n",
       "Bigram_best_NB        0.937383       0.555746     0.933297    0.000458   \n",
       "Trigram_best_NB       0.937387       0.555688     0.933304    0.000452   \n",
       "\n",
       "                 CV_F1_score  \n",
       "Raw_token_NB        0.548922  \n",
       "Token_NB            0.530513  \n",
       "Bigram_NB           0.481289  \n",
       "Trigram_NB          0.508322  \n",
       "Tfidf_t_NB          0.112072  \n",
       "Bigram_best_NB      0.533363  \n",
       "Trigram_best_NB     0.533348  "
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model_label = 'Raw_token_NB'\n",
    "\n",
    "model_score(model, X_train_raw_t, X_test_raw_t, y_train_raw, y_test_raw, score_df, model_label)\n",
    "cv_score(model, X_train_raw_t, y_train_raw, model_label)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.9350739237089765\n",
      "test score: 0.9344135778838762\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_raw_t, y_train_raw)  \n",
    "test_score =  nb.score(X_test_raw_t, y_test_raw)\n",
    "print('train score:', nb.score(X_train_raw_t, y_train_raw))\n",
    "print('test score:', test_score)\n",
    "y_pred = nb.predict(X_test_raw_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5646092542896641\n",
      "0.7645724512273393\n",
      "0.9344135778838762\n",
      "0.9397915566837656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[291229,  15099],\n",
       "       [  6317,  13886]], dtype=int64)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f1_score(y_test_raw, y_pred) )\n",
    "print(f1_score(y_test_raw, y_pred, average='macro') )\n",
    "print(f1_score(y_test_raw, y_pred, average='micro') )\n",
    "print(f1_score(y_test_raw, y_pred, average='weighted') )\n",
    "confusion_matrix(y_test_raw, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Token and Ngram modelling on cleaned data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = clean_questions\n",
    "y = train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state = 495)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokens only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 20.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_t, X_test_t=  vect_trans(CountVectorizer(max_df=1.0, min_df=1, ngram_range=(1,1)), X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.9375157591280443\n",
      "Test Accuracy: 0.9368084500399656\n",
      "Test F1 score: 0.5530864197530864\n",
      "Test Accuracy Mean: 0.9322002750907756\n",
      "Test Accuracy STD: 0.0004858539885341205\n",
      "Test F1: 0.5273019796267486\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>Test_F1_score</th>\n",
       "      <th>CV_Accuracy</th>\n",
       "      <th>CV_Acc_STD</th>\n",
       "      <th>CV_F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Raw_token_NB</th>\n",
       "      <td>0.934414</td>\n",
       "      <td>0.564609</td>\n",
       "      <td>0.932161</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.548922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Token_NB</th>\n",
       "      <td>0.936808</td>\n",
       "      <td>0.553086</td>\n",
       "      <td>0.932200</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.527302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bigram_NB</th>\n",
       "      <td>0.947245</td>\n",
       "      <td>0.396637</td>\n",
       "      <td>0.944612</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.481289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trigram_NB</th>\n",
       "      <td>0.944777</td>\n",
       "      <td>0.271846</td>\n",
       "      <td>0.944942</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.508322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf_t_NB</th>\n",
       "      <td>0.941736</td>\n",
       "      <td>0.147893</td>\n",
       "      <td>0.940431</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.112072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bigram_best_NB</th>\n",
       "      <td>0.937383</td>\n",
       "      <td>0.555746</td>\n",
       "      <td>0.933297</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.533363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trigram_best_NB</th>\n",
       "      <td>0.937387</td>\n",
       "      <td>0.555688</td>\n",
       "      <td>0.933304</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.533348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Test_Accuracy  Test_F1_score  CV_Accuracy  CV_Acc_STD  \\\n",
       "Raw_token_NB          0.934414       0.564609     0.932161    0.000523   \n",
       "Token_NB              0.936808       0.553086     0.932200    0.000486   \n",
       "Bigram_NB             0.947245       0.396637     0.944612    0.000376   \n",
       "Trigram_NB            0.944777       0.271846     0.944942    0.000415   \n",
       "Tfidf_t_NB            0.941736       0.147893     0.940431    0.000149   \n",
       "Bigram_best_NB        0.937383       0.555746     0.933297    0.000458   \n",
       "Trigram_best_NB       0.937387       0.555688     0.933304    0.000452   \n",
       "\n",
       "                 CV_F1_score  \n",
       "Raw_token_NB        0.548922  \n",
       "Token_NB            0.527302  \n",
       "Bigram_NB           0.481289  \n",
       "Trigram_NB          0.508322  \n",
       "Tfidf_t_NB          0.112072  \n",
       "Bigram_best_NB      0.533363  \n",
       "Trigram_best_NB     0.533348  "
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model_label = 'Token_NB'\n",
    "X_train_arg = X_train_t\n",
    "X_test_arg = X_test_t\n",
    "\n",
    "model_score(model, X_train_arg, X_test_arg, y_train, y_test, score_df, model_label)\n",
    "cv_score(model, X_train_arg, y_train, model_label)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 58.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_bi, X_test_bi=  vect_trans(CountVectorizer(ngram_range=(1,2)), X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.9739381027387961\n",
      "Test Accuracy: 0.9469973754406167\n",
      "Test F1 score: 0.3953463997484541\n",
      "Test Accuracy Mean: 0.9443043071510162\n",
      "Test Accuracy STD: 0.0004189333820907424\n",
      "Test F1: 0.4772300836991656\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>Test_F1_score</th>\n",
       "      <th>CV_Accuracy</th>\n",
       "      <th>CV_Acc_STD</th>\n",
       "      <th>CV_F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Raw_token_NB</th>\n",
       "      <td>0.934414</td>\n",
       "      <td>0.564609</td>\n",
       "      <td>0.932161</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.548922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Token_NB</th>\n",
       "      <td>0.936808</td>\n",
       "      <td>0.553086</td>\n",
       "      <td>0.932200</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.527302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bigram_NB</th>\n",
       "      <td>0.946997</td>\n",
       "      <td>0.395346</td>\n",
       "      <td>0.944304</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.477230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trigram_NB</th>\n",
       "      <td>0.944777</td>\n",
       "      <td>0.271846</td>\n",
       "      <td>0.944942</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.508322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf_t_NB</th>\n",
       "      <td>0.941736</td>\n",
       "      <td>0.147893</td>\n",
       "      <td>0.940431</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.112072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bigram_best_NB</th>\n",
       "      <td>0.937383</td>\n",
       "      <td>0.555746</td>\n",
       "      <td>0.933297</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.533363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trigram_best_NB</th>\n",
       "      <td>0.937387</td>\n",
       "      <td>0.555688</td>\n",
       "      <td>0.933304</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.533348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Test_Accuracy  Test_F1_score  CV_Accuracy  CV_Acc_STD  \\\n",
       "Raw_token_NB          0.934414       0.564609     0.932161    0.000523   \n",
       "Token_NB              0.936808       0.553086     0.932200    0.000486   \n",
       "Bigram_NB             0.946997       0.395346     0.944304    0.000419   \n",
       "Trigram_NB            0.944777       0.271846     0.944942    0.000415   \n",
       "Tfidf_t_NB            0.941736       0.147893     0.940431    0.000149   \n",
       "Bigram_best_NB        0.937383       0.555746     0.933297    0.000458   \n",
       "Trigram_best_NB       0.937387       0.555688     0.933304    0.000452   \n",
       "\n",
       "                 CV_F1_score  \n",
       "Raw_token_NB        0.548922  \n",
       "Token_NB            0.527302  \n",
       "Bigram_NB           0.477230  \n",
       "Trigram_NB          0.508322  \n",
       "Tfidf_t_NB          0.112072  \n",
       "Bigram_best_NB      0.533363  \n",
       "Trigram_best_NB     0.533348  "
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model_label = 'Bigram_NB'\n",
    "X_train_arg = X_train_bi\n",
    "X_test_arg = X_test_bi\n",
    "\n",
    "model_score(model, X_train_arg, X_test_arg, y_train, y_test, score_df, model_label)\n",
    "cv_score(model, X_train_arg, y_train, model_label)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# model = RandomForestClassifier(n_estimators= 100, max_depth=20, n_jobs=-1)\n",
    "# model_label = 'Bigram_RF'\n",
    "\n",
    "\n",
    "# model_score(model, X_train_bi, X_test_bi, y_train, y_test, score_df, model_label)\n",
    "# cv_score(model, X_train_bi, y_train, model_label)\n",
    "# score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tri-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_tri, X_test_tri=  vect_trans(CountVectorizer(ngram_range=(1,3), stop_words=stopwords), X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.987748968702244\n",
      "Test Accuracy: 0.9445810658099844\n",
      "Test F1 score: 0.26937984496124034\n",
      "Test Accuracy Mean: 0.9445799319383473\n",
      "Test Accuracy STD: 0.0003738154615595804\n",
      "Test F1: 0.5034396610971816\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>Test_F1_score</th>\n",
       "      <th>CV_Accuracy</th>\n",
       "      <th>CV_Acc_STD</th>\n",
       "      <th>CV_F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Raw_token_NB</th>\n",
       "      <td>0.934414</td>\n",
       "      <td>0.564609</td>\n",
       "      <td>0.932161</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.548922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Token_NB</th>\n",
       "      <td>0.936808</td>\n",
       "      <td>0.553086</td>\n",
       "      <td>0.932200</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.527302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bigram_NB</th>\n",
       "      <td>0.946997</td>\n",
       "      <td>0.395346</td>\n",
       "      <td>0.944304</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.477230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trigram_NB</th>\n",
       "      <td>0.944581</td>\n",
       "      <td>0.269380</td>\n",
       "      <td>0.944580</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>0.503440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf_t_NB</th>\n",
       "      <td>0.941736</td>\n",
       "      <td>0.147893</td>\n",
       "      <td>0.940431</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.112072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bigram_best_NB</th>\n",
       "      <td>0.937383</td>\n",
       "      <td>0.555746</td>\n",
       "      <td>0.933297</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.533363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trigram_best_NB</th>\n",
       "      <td>0.937387</td>\n",
       "      <td>0.555688</td>\n",
       "      <td>0.933304</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.533348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Test_Accuracy  Test_F1_score  CV_Accuracy  CV_Acc_STD  \\\n",
       "Raw_token_NB          0.934414       0.564609     0.932161    0.000523   \n",
       "Token_NB              0.936808       0.553086     0.932200    0.000486   \n",
       "Bigram_NB             0.946997       0.395346     0.944304    0.000419   \n",
       "Trigram_NB            0.944581       0.269380     0.944580    0.000374   \n",
       "Tfidf_t_NB            0.941736       0.147893     0.940431    0.000149   \n",
       "Bigram_best_NB        0.937383       0.555746     0.933297    0.000458   \n",
       "Trigram_best_NB       0.937387       0.555688     0.933304    0.000452   \n",
       "\n",
       "                 CV_F1_score  \n",
       "Raw_token_NB        0.548922  \n",
       "Token_NB            0.527302  \n",
       "Bigram_NB           0.477230  \n",
       "Trigram_NB          0.503440  \n",
       "Tfidf_t_NB          0.112072  \n",
       "Bigram_best_NB      0.533363  \n",
       "Trigram_best_NB     0.533348  "
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model_label = 'Trigram_NB'\n",
    "X_train_arg = X_train_tri\n",
    "X_test_arg = X_test_tri\n",
    "\n",
    "model_score(model, X_train_arg, X_test_arg, y_train, y_test, score_df, model_label)\n",
    "cv_score(model, X_train_arg, y_train, model_label)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# model = RandomForestClassifier(n_estimators= 100, max_depth=20, n_jobs=-1)\n",
    "# model_label = 'Trigram_RF'\n",
    "\n",
    "# model_score(model, X_train_tri, X_test_tri, y_train, y_test, score_df, model_label)\n",
    "# cv_score(model, X_train_tri, y_train, model_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch min/max df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {'CV__max_df':(1.0, 0.9),\n",
    "#        'CV__min_df': (1, 2, 0.01, 0.02),\n",
    "#         'CV__ngram_range':((1,1), (1,2), (1,3))}\n",
    "\n",
    "# gridcv(pipeCVNB, X_train, y_train, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# X_train_t, X_test_t=  vect_trans(CountVectorizer(max_df=1.0, min_df=1, ngram_range=(1,2), \n",
    "#                                                     stop_words=stopwords), X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = MultinomialNB()\n",
    "# model_label = 'Grid_DFNB'\n",
    "\n",
    "# model_score(model, X_train_t, X_test_t, y_train, y_test, score_df, model_label)\n",
    "# cv_score(model, X_train_t, y_train, model_label)\n",
    "# score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tf_t, X_test_tf_t = vect_trans(TfidfTransformer(), X_train_t, X_test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.9426342218333978\n",
      "Test Accuracy: 0.9411663823649209\n",
      "Test F1 score: 0.12847616023227326\n",
      "Test Accuracy Mean: 0.940048449146909\n",
      "Test Accuracy STD: 0.0001397279742376803\n",
      "Test F1: 0.09784554938584501\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>Test_F1_score</th>\n",
       "      <th>CV_Accuracy</th>\n",
       "      <th>CV_Acc_STD</th>\n",
       "      <th>CV_F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Raw_token_NB</th>\n",
       "      <td>0.934414</td>\n",
       "      <td>0.564609</td>\n",
       "      <td>0.932161</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.548922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Token_NB</th>\n",
       "      <td>0.936808</td>\n",
       "      <td>0.553086</td>\n",
       "      <td>0.932200</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.527302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bigram_NB</th>\n",
       "      <td>0.946997</td>\n",
       "      <td>0.395346</td>\n",
       "      <td>0.944304</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.477230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trigram_NB</th>\n",
       "      <td>0.944581</td>\n",
       "      <td>0.269380</td>\n",
       "      <td>0.944580</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>0.503440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf_t_NB</th>\n",
       "      <td>0.941166</td>\n",
       "      <td>0.128476</td>\n",
       "      <td>0.940048</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.097846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bigram_best_NB</th>\n",
       "      <td>0.937383</td>\n",
       "      <td>0.555746</td>\n",
       "      <td>0.933297</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.533363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trigram_best_NB</th>\n",
       "      <td>0.937387</td>\n",
       "      <td>0.555688</td>\n",
       "      <td>0.933304</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.533348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Test_Accuracy  Test_F1_score  CV_Accuracy  CV_Acc_STD  \\\n",
       "Raw_token_NB          0.934414       0.564609     0.932161    0.000523   \n",
       "Token_NB              0.936808       0.553086     0.932200    0.000486   \n",
       "Bigram_NB             0.946997       0.395346     0.944304    0.000419   \n",
       "Trigram_NB            0.944581       0.269380     0.944580    0.000374   \n",
       "Tfidf_t_NB            0.941166       0.128476     0.940048    0.000140   \n",
       "Bigram_best_NB        0.937383       0.555746     0.933297    0.000458   \n",
       "Trigram_best_NB       0.937387       0.555688     0.933304    0.000452   \n",
       "\n",
       "                 CV_F1_score  \n",
       "Raw_token_NB        0.548922  \n",
       "Token_NB            0.527302  \n",
       "Bigram_NB           0.477230  \n",
       "Trigram_NB          0.503440  \n",
       "Tfidf_t_NB          0.097846  \n",
       "Bigram_best_NB      0.533363  \n",
       "Trigram_best_NB     0.533348  "
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model_label = 'Tfidf_t_NB'\n",
    "\n",
    "model_score(model, X_train_tf_t , X_test_tf_t, y_train, y_test, score_df, model_label)\n",
    "cv_score(model, X_train_tf_t, y_train, model_label)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.9426342218333978\n",
      "test score: 0.9411663823649209\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_tf_t, y_train)  \n",
    "test_score =  nb.score(X_test_tf_t, y_test)\n",
    "print('train score:', nb.score(X_train_tf_t, y_train))\n",
    "print('test score:', test_score)\n",
    "y_pred = nb.predict(X_test_tf_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12847616023227326\n",
      "0.5490158760303643\n",
      "0.9411663823649209\n",
      "0.9175166498703021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[305904,    424],\n",
       "       [ 18787,   1416]], dtype=int64)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f1_score(y_test, y_pred) )\n",
    "print(f1_score(y_test, y_pred, average='macro') )\n",
    "print(f1_score(y_test, y_pred, average='micro') )\n",
    "print(f1_score(y_test, y_pred, average='weighted') )\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK Best Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreate text using ngrams\n",
    "def ngram_to_corpus(data, ngram_list, n):\n",
    "#     ngram_list = set({('let', 'us'), ('as', 'soon')})  # {('let', 'us'), ('as', 'soon')}\n",
    "#     tokens = ['please', 'let', 'us', 'know', 'as', 'soon', 'as', 'possible']\n",
    "    new_data = []\n",
    "    for text in data:\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        output = []\n",
    "        q_iter = iter(range(len(tokens)))\n",
    "        \n",
    "        for idx in q_iter:\n",
    "            output.append(tokens[idx])\n",
    "            if n == 2:\n",
    "                if idx < (len(tokens) - 1) and (tokens[idx], tokens[idx+1]) in ngram_list:\n",
    "                    output[-1] += '_' + tokens[idx+1]\n",
    "                    next(q_iter)\n",
    "            elif n == 3:\n",
    "                if idx < (len(tokens) - 2) and (tokens[idx], tokens[idx+1], tokens[idx+2] ) in ngram_list:\n",
    "                    output[-1] += '_' + tokens[idx+1] + '_' + tokens[idx+2]\n",
    "                    next(q_iter)\n",
    "                    next(q_iter)\n",
    "        new_data.append( ' '.join(output))\n",
    "\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create one list of all question tokens\n",
    "full_text = []\n",
    "\n",
    "for text in X_train:\n",
    "    full_text += [w for w in nltk.word_tokenize(text) if w not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6274209"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'would' in stopwords:\n",
    "    print(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('united', 'states'), ('year', 'old'), ('best', 'way'), ('donald', 'trump'), ('computer', 'science'), ('even', 'though'), ('high', 'school'), ('social', 'media'), ('would', 'happen'), ('north', 'korea'), ('pros', 'cons'), ('get', 'rid'), ('major', 'accomplishments'), ('jee', 'mains'), ('look', 'like'), ('would', 'win'), ('x', 'x'), ('new', 'york'), ('machine', 'learning'), ('harry', 'potter'), ('years', 'old'), ('real', 'estate'), ('ssc', 'cgl'), ('long', 'take'), ('saudi', 'arabia'), ('feel', 'like'), ('star', 'wars'), ('long', 'term'), ('mechanical', 'engineering'), ('elon', 'musk'), ('tv', 'show'), ('e', 'g'), ('hillary', 'clinton'), ('hong', 'kong'), ('tamil', 'nadu'), ('short', 'term'), ('president', 'trump'), ('useful', 'tips'), ('san', 'francisco'), ('b', 'tech'), ('artificial', 'intelligence'), ('prime', 'minister'), ('different', 'types'), ('tv', 'series'), ('years', 'ago'), ('credit', 'card'), ('literary', 'devices'), ('narendra', 'modi'), ('new', 'zealand'), ('many', 'people'), ('digital', 'marketing'), ('los', 'angeles'), ('win', 'fight'), ('someone', 'else'), ('get', 'job'), ('middle', 'east'), ('vice', 'versa'), ('stock', 'market'), ('kim', 'jong'), ('jee', 'advanced'), ('earn', 'money'), ('mental', 'illness'), ('civil', 'engineering'), ('advantages', 'disadvantages'), ('real', 'life'), ('lose', 'weight'), ('make', 'money'), ('much', 'money'), ('trump', 'supporters'), ('black', 'hole'), ('chances', 'getting'), ('youtube', 'channel'), ('south', 'korea'), ('programming', 'language'), ('jong', 'un'), ('south', 'africa'), ('hotels', 'short'), ('get', 'admission'), ('best', 'ways'), ('global', 'warming')]\n",
      "Wall time: 54.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create bigram vocabulary\n",
    "bigram_measures = collocations.BigramAssocMeasures()\n",
    "\n",
    "finder = nltk.BigramCollocationFinder.from_words(full_text)\n",
    "# scored = finder.score_ngrams( bigram_measures.likelihood_ratio  )\n",
    "bigram_vocab = finder.nbest(bigram_measures.likelihood_ratio, 80)\n",
    "print(bigram_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('schr', 'dinger'), ('pepto', 'bismol'), ('michio', 'kaku'), ('neman', 'ashraf'), ('roald', 'dahl'), ('rudyard', 'kipling'), ('muhoozi', 'kainerugaba'), ('avada', 'kedavra'), ('aam', 'aadmi'), ('buenos', 'aires'), ('jaggi', 'vasudev'), ('disha', 'patani'), ('ronda', 'rousey'), ('abercrombie', 'fitch'), ('mosin', 'nagant'), ('zaira', 'wasim'), ('endoplasmic', 'reticulum'), ('deng', 'xiaoping'), ('gilgit', 'baltistan'), ('nathuram', 'godse'), ('sushma', 'swaraj'), ('jiang', 'zemin'), ('vande', 'mataram'), ('meryl', 'streep'), ('pakatan', 'harapan'), ('asim', 'qureshi'), ('sylvia', 'plath'), ('lata', 'mangeshkar'), ('sindhu', 'satish'), ('dima', 'vorobiev'), ('kalpit', 'veerwal'), ('pradhan', 'mantri'), ('aldous', 'huxley'), ('narsee', 'monjee'), ('ulcerative', 'colitis'), ('gauri', 'lankesh'), ('hadron', 'collider'), ('ballon', \"d'or\"), ('jiu', 'jitsu'), ('shel', 'silverstein'), ('mitt', 'romney'), ('khaled', 'hosseini'), ('petyr', 'baelish'), ('sourav', 'ganguly'), ('satoshi', 'nakamoto'), ('satya', 'nadella'), ('agatha', 'christie'), ('tubal', 'ligation'), ('jules', 'verne'), ('jimi', 'hendrix'), ('smriti', 'irani'), ('klux', 'klan'), ('raghuram', 'rajan'), ('shweta', 'shalini'), ('yoko', 'ono'), ('lingua', 'franca'), ('nigel', 'farage'), ('scooby', 'doo'), ('snoop', 'dogg'), ('jorah', 'mormont'), ('tic', 'tac'), ('forrest', 'gump'), ('scarlett', 'johansson'), ('nicki', 'minaj'), ('hrithik', 'roshan'), ('stony', 'brook'), ('trinidad', 'tobago'), ('dushka', 'zapata'), ('shinzo', 'abe'), ('nath', 'kovind'), ('fran', 'ois'), ('magna', 'carta'), ('rudy', 'giuliani'), ('kendriya', 'vidyalaya'), ('barkha', 'dutt'), ('chester', 'bennington'), ('falun', 'gong'), ('rabindranath', 'tagore'), ('vinay', 'kumaran'), ('arsene', 'wenger'), ('hafiz', 'saeed'), ('reza', 'pahlavi'), ('granth', 'sahib'), ('dawood', 'ibrahim'), ('ajit', 'pai'), ('sergey', 'brin'), ('notre', 'dame'), ('ravindrababu', 'ravula'), ('tsar', 'bomba'), ('mustafa', 'kemal'), ('waldo', 'emerson'), ('che', 'guevara'), ('kendrick', 'lamar'), ('elke', 'weiss'), ('mein', 'kampf'), ('sandeep', 'maheshwari'), ('britney', 'spears'), ('kellyanne', 'conway'), ('magnus', 'carlsen'), ('alia', 'bhatt'), ('mace', 'windu'), ('deathly', 'hallows'), ('kyrie', 'irving'), ('spongebob', 'squarepants'), ('winnie', 'pooh'), ('looney', 'tunes'), ('milo', 'yiannopoulos'), ('shawshank', 'redemption'), ('lex', 'luthor'), ('hannibal', 'lecter'), ('boba', 'fett'), ('lois', 'lowry'), ('terence', 'tao'), ('zack', 'snyder'), ('dalai', 'lama'), ('aurora', 'borealis'), ('brock', 'lesnar'), ('krav', 'maga'), ('nawaz', 'sharif'), ('zakir', 'naik'), ('noam', 'chomsky'), ('hans', 'zimmer'), ('fullmetal', 'alchemist'), ('hugh', 'hefner'), ('mar', 'lago'), ('sundar', 'pichai'), ('tel', 'aviv'), ('berkshire', 'hathaway'), ('chiang', 'mai'), ('ku', 'klux'), ('stephenie', 'meyer'), ('fidel', 'castro'), ('oprah', 'winfrey'), ('subramanian', 'swamy'), ('shashi', 'tharoor'), ('kj', 'somaiya'), ('miley', 'cyrus'), ('burj', 'khalifa'), ('travis', 'kalanick'), ('muammar', 'gaddafi'), ('paulo', 'coelho'), ('atat', 'rk'), ('ralph', 'waldo'), ('karni', 'sena'), ('kurt', 'cobain'), ('peyton', 'manning'), ('catcher', 'rye'), ('moderated', 'caucus'), ('ariana', 'grande'), ('acm', 'icpc'), ('otto', 'warmbier'), ('ivan', 'tregear'), ('dhinchak', 'pooja'), ('solitary', 'confinement'), ('bosnia', 'herzegovina'), ('ku', 'leuven'), ('mitch', 'mcconnell'), ('andaman', 'nicobar'), ('majin', 'buu'), ('consiglio', 'devastations'), ('monte', 'carlo'), ('habib', 'fanny'), ('kulbhushan', 'jadhav'), ('brad', 'pitt'), ('bunsen', 'burner'), ('shin', 'splints'), ('netaji', 'subhash'), ('aishwarya', 'rai'), ('selena', 'gomez'), ('truman', 'capote'), ('dennis', 'rodman'), ('euron', 'greyjoy'), ('deepika', 'padukone'), ('tipu', 'sultan'), ('jill', 'stein'), ('julian', 'assange'), ('martian', 'manhunter'), ('katrina', 'kaif'), ('arnab', 'goswami'), ('maya', 'angelou'), ('conor', 'mcgregor'), ('kung', 'fu'), ('amitabh', 'bachchan'), ('sergei', 'skripal'), ('arun', 'jaitley'), ('ping', 'pong'), ('marilyn', 'monroe'), ('palo', 'alto'), ('nikki', 'haley'), ('pawan', 'kalyan'), ('sigmund', 'freud'), ('ayn', 'rand'), ('dunkin', 'donuts'), ('millia', 'islamia'), ('nova', 'scotia'), ('degrasse', 'tyson'), ('inguinal', 'hernia'), ('buzz', 'aldrin'), ('kemal', 'ataturk'), ('rachel', 'maddow')]\n",
      "Wall time: 18.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create bigram vocabulary\n",
    "bigram_measures = collocations.BigramAssocMeasures()\n",
    "\n",
    "\n",
    "finder3 = nltk.BigramCollocationFinder.from_words(full_text)\n",
    "finder3.apply_freq_filter(10)\n",
    "finder3.apply_word_filter(lambda x: x in stopwords)\n",
    "best_pmi = finder3.nbest(bigram_measures.pmi, 200)\n",
    "print(best_pmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('united', 'states', 'america'), ('president', 'united', 'states'), ('united', 'states', 'india'), ('states', 'united', 'states'), ('history', 'united', 'states'), ('united', 'states', 'constitution'), ('united', 'states', 'government'), ('united', 'states', 'matter'), ('united', 'states', 'like'), ('united', 'states', 'army'), ('united', 'states', 'usa'), ('united', 'states', 'us'), ('united', 'states', 'united'), ('coast', 'united', 'states'), ('south', 'united', 'states'), ('canada', 'united', 'states'), ('united', 'states', 'military'), ('united', 'states', 'marine'), ('outside', 'united', 'states'), ('happen', 'united', 'states')]\n",
      "Wall time: 8min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create trigram vocabulary\n",
    "trigram_measures = collocations.TrigramAssocMeasures()\n",
    "finder = nltk.TrigramCollocationFinder.from_words(full_text)\n",
    "trigram_vocab = finder.nbest(trigram_measures.likelihood_ratio, 20)\n",
    "print(trigram_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create text with bigram replacement\n",
    "train['bigram_question_lkhd'] = ngram_to_corpus(clean_questions, bigram_vocab, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create text with both tri and bigram in text, by applying trigram first\n",
    "train['trigram_question_lkhd'] = ngram_to_corpus(clean_questions, trigram_vocab, 3)\n",
    "train['trigram_question_lkhd'] = ngram_to_corpus(train['trigram_question_lkhd'], bigram_vocab, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['know whether girl done sex sex',\n",
       "       'become fast learner professional career personal life',\n",
       "       'united_states become largest dictatorship world',\n",
       "       'strangest phenomenon know witnessed generated area electronics explanation terms modern physics',\n",
       "       'leave friends find new ones'], dtype=object)"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['trigram_question_lkhd'][20:25].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[['bigram_question_lkhd','trigram_question_lkhd']]\n",
    "y = train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=495, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1044897"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram_question_lkhd</th>\n",
       "      <th>trigram_question_lkhd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1077331</th>\n",
       "      <td>procedure officially changing name india</td>\n",
       "      <td>procedure officially changing name india</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334276</th>\n",
       "      <td>ancient egypt polytheism</td>\n",
       "      <td>ancient egypt polytheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620299</th>\n",
       "      <td>whenever put blood pressure monitor get scared...</td>\n",
       "      <td>whenever put blood pressure monitor get scared...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098236</th>\n",
       "      <td>ego react suicide</td>\n",
       "      <td>ego react suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548923</th>\n",
       "      <td>join tcs fresher missed campus hiring</td>\n",
       "      <td>join tcs fresher missed campus hiring</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      bigram_question_lkhd  \\\n",
       "1077331           procedure officially changing name india   \n",
       "334276                            ancient egypt polytheism   \n",
       "620299   whenever put blood pressure monitor get scared...   \n",
       "1098236                                  ego react suicide   \n",
       "548923               join tcs fresher missed campus hiring   \n",
       "\n",
       "                                     trigram_question_lkhd  \n",
       "1077331           procedure officially changing name india  \n",
       "334276                            ancient egypt polytheism  \n",
       "620299   whenever put blood pressure monitor get scared...  \n",
       "1098236                                  ego react suicide  \n",
       "548923               join tcs fresher missed campus hiring  "
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model using bigram text\n",
    "X_train_bi, X_test_bi =  vect_trans(CountVectorizer(max_df=1.0,  min_df=1, ngram_range=(1,1), stop_words=stopwords),\n",
    "                                   X_train.bigram_question_lkhd, X_test.bigram_question_lkhd,)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.9380637517382096\n",
      "Test Accuracy: 0.9370466073308451\n",
      "Test F1 score: 0.5530885670027448\n",
      "Test Accuracy Mean: 0.9328287866087697\n",
      "Test Accuracy STD: 0.0004956699857974989\n",
      "Test F1: 0.5299533440504494\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>Test_F1_score</th>\n",
       "      <th>CV_Accuracy</th>\n",
       "      <th>CV_Acc_STD</th>\n",
       "      <th>CV_F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Raw_token_NB</th>\n",
       "      <td>0.934414</td>\n",
       "      <td>0.564609</td>\n",
       "      <td>0.932161</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.548922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Token_NB</th>\n",
       "      <td>0.936808</td>\n",
       "      <td>0.553086</td>\n",
       "      <td>0.932200</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.527302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bigram_NB</th>\n",
       "      <td>0.946997</td>\n",
       "      <td>0.395346</td>\n",
       "      <td>0.944304</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.477230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trigram_NB</th>\n",
       "      <td>0.944581</td>\n",
       "      <td>0.269380</td>\n",
       "      <td>0.944580</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>0.503440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf_t_NB</th>\n",
       "      <td>0.941166</td>\n",
       "      <td>0.128476</td>\n",
       "      <td>0.940048</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.097846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bigram_best_NB</th>\n",
       "      <td>0.937047</td>\n",
       "      <td>0.553089</td>\n",
       "      <td>0.932829</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.529953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trigram_best_NB</th>\n",
       "      <td>0.937387</td>\n",
       "      <td>0.555688</td>\n",
       "      <td>0.933304</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.533348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Test_Accuracy  Test_F1_score  CV_Accuracy  CV_Acc_STD  \\\n",
       "Raw_token_NB          0.934414       0.564609     0.932161    0.000523   \n",
       "Token_NB              0.936808       0.553086     0.932200    0.000486   \n",
       "Bigram_NB             0.946997       0.395346     0.944304    0.000419   \n",
       "Trigram_NB            0.944581       0.269380     0.944580    0.000374   \n",
       "Tfidf_t_NB            0.941166       0.128476     0.940048    0.000140   \n",
       "Bigram_best_NB        0.937047       0.553089     0.932829    0.000496   \n",
       "Trigram_best_NB       0.937387       0.555688     0.933304    0.000452   \n",
       "\n",
       "                 CV_F1_score  \n",
       "Raw_token_NB        0.548922  \n",
       "Token_NB            0.527302  \n",
       "Bigram_NB           0.477230  \n",
       "Trigram_NB          0.503440  \n",
       "Tfidf_t_NB          0.097846  \n",
       "Bigram_best_NB      0.529953  \n",
       "Trigram_best_NB     0.533348  "
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model_label = 'Bigram_best_NB'\n",
    "\n",
    "model_score(model, X_train_bi, X_test_bi, y_train, y_test, score_df, model_label)\n",
    "cv_score(model, X_train_bi, y_train, model_label)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model using bigram text\n",
    "X_train_tri, X_test_tri =  vect_trans(CountVectorizer(max_df=1.0,  min_df=1, ngram_range=(1,1), stop_words=stopwords),\n",
    "                                   X_train.trigram_question_lkhd, X_test.trigram_question_lkhd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.9380752361237519\n",
      "Test Accuracy: 0.9370657479184611\n",
      "Test F1 score: 0.5531394400652351\n",
      "Test Accuracy Mean: 0.9328354858098556\n",
      "Test Accuracy STD: 0.0004794080104813063\n",
      "Test F1: 0.5299405877493948\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>Test_F1_score</th>\n",
       "      <th>CV_Accuracy</th>\n",
       "      <th>CV_Acc_STD</th>\n",
       "      <th>CV_F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Raw_token_NB</th>\n",
       "      <td>0.934414</td>\n",
       "      <td>0.564609</td>\n",
       "      <td>0.932161</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.548922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Token_NB</th>\n",
       "      <td>0.936808</td>\n",
       "      <td>0.553086</td>\n",
       "      <td>0.932200</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.527302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bigram_NB</th>\n",
       "      <td>0.946997</td>\n",
       "      <td>0.395346</td>\n",
       "      <td>0.944304</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.477230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trigram_NB</th>\n",
       "      <td>0.944581</td>\n",
       "      <td>0.269380</td>\n",
       "      <td>0.944580</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>0.503440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf_t_NB</th>\n",
       "      <td>0.941166</td>\n",
       "      <td>0.128476</td>\n",
       "      <td>0.940048</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.097846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bigram_best_NB</th>\n",
       "      <td>0.937047</td>\n",
       "      <td>0.553089</td>\n",
       "      <td>0.932829</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.529953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trigram_best_NB</th>\n",
       "      <td>0.937066</td>\n",
       "      <td>0.553139</td>\n",
       "      <td>0.932835</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>0.529941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Test_Accuracy  Test_F1_score  CV_Accuracy  CV_Acc_STD  \\\n",
       "Raw_token_NB          0.934414       0.564609     0.932161    0.000523   \n",
       "Token_NB              0.936808       0.553086     0.932200    0.000486   \n",
       "Bigram_NB             0.946997       0.395346     0.944304    0.000419   \n",
       "Trigram_NB            0.944581       0.269380     0.944580    0.000374   \n",
       "Tfidf_t_NB            0.941166       0.128476     0.940048    0.000140   \n",
       "Bigram_best_NB        0.937047       0.553089     0.932829    0.000496   \n",
       "Trigram_best_NB       0.937066       0.553139     0.932835    0.000479   \n",
       "\n",
       "                 CV_F1_score  \n",
       "Raw_token_NB        0.548922  \n",
       "Token_NB            0.527302  \n",
       "Bigram_NB           0.477230  \n",
       "Trigram_NB          0.503440  \n",
       "Tfidf_t_NB          0.097846  \n",
       "Bigram_best_NB      0.529953  \n",
       "Trigram_best_NB     0.529941  "
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model_label = 'Trigram_best_NB'\n",
    "\n",
    "model_score(model, X_train_tri, X_test_tri, y_train, y_test, score_df, model_label)\n",
    "cv_score(model, X_train_tri, y_train, model_label)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score_df.to_pickle('./lemmaID_score.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = pd.read_pickle('./lemma_score.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df = pd.DataFrame(index=['Baseline','Raw Token', 'Tokens', 'All Bigram', 'All Trigram', 'TFIDF', 'N Bigram', 'N Trigram'])\n",
    "acc_df['Accuracy'] = acc_list = [1-train.target.mean()] + list(score_df['Test_Accuracy'][:7])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_df =  pd.DataFrame(index=['Raw Token', 'Tokens', 'All Bigram', 'All Trigram', 'TFIDF', 'N Bigram', 'N Trigram'])\n",
    "f1_df['F1 Score'] = list(score_df['Test_F1_score'][:7])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "style.use('seaborn-poster')\n",
    "\n",
    "style.use('seaborn-whitegrid') #sets the size of the charts\n",
    "style.use('tableau-colorblind10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_color = ['grey', 'coral', 'coral','coral','coral','coral','coral','coral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x576 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(18,8))\n",
    "\n",
    "ax1 = plt.subplot(121)\n",
    "ax1 = sns.barplot(x=f1_df.index, y=f1_df['F1 Score'], color='cornflowerblue')\n",
    "ax1 = plt.ylim(0, 0.7)\n",
    "ax1 = plt.xticks(rotation=45)\n",
    "ax1 = plt.title('F1 Score')\n",
    "ax1 = plt.ylabel('')\n",
    "\n",
    "\n",
    "ax2 = plt.subplot(122)\n",
    "ax2 = sns.barplot(x=acc_df.index, y=acc_df.Accuracy, palette=acc_color)\n",
    "ax2 = plt.ylim(0.9, 1)\n",
    "ax2 = plt.xticks(rotation=45)\n",
    "ax2 = plt.title('Accuracy')\n",
    "ax2 = plt.ylabel('')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
