{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text manipulation\n",
    "import re\n",
    "import string\n",
    "\n",
    "# Data management\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import *\n",
    "import scipy\n",
    "\n",
    "# NLP\n",
    "import nltk\n",
    "import nltk.collocations as collocations\n",
    "from nltk.tag import tnt\n",
    "import spacy\n",
    "\n",
    "# modelling\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "\n",
    "#visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
       "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
       "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
       "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1306122, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of insincere questions: 80810\n",
      "No. of sincere questions: 1225312\n",
      "% of insincere questions: 0.06187017751787352\n",
      "Null score: 0.9381298224821265\n"
     ]
    }
   ],
   "source": [
    "no_insincere = train[train['target']==1].target.count()\n",
    "no_sincere = train[train['target']==0].target.count()\n",
    "\n",
    "print('No. of insincere questions:', no_insincere)\n",
    "print('No. of sincere questions:', no_sincere)\n",
    "print('% of insincere questions:', train.target.mean())\n",
    "print('Null score:', 1- train.target.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of lanuages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lang_list = set([langid.classify(s)[0] for s in train['question_text']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Some are questions in different lanuages, some are questions regarding different lanuages.\n",
    "# basic_stats['no_of_lang'] = len(lang_list)\n",
    "# basic_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.question_text\n",
    "y = train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state = 495)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions and pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vect_trans(vectorizer, X_train, X_test):\n",
    "    # can also take a transformer\n",
    "    vect = vectorizer\n",
    "    vect.fit(X_train)\n",
    "    return vect.transform(X_train), vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultinominalNB function for printing scores and storing into df.\n",
    "def model_score(model, X_train, X_test, y_train, y_test, score_df, model_label):\n",
    "    estimator = model\n",
    "    estimator.fit(X_train, y_train)\n",
    "    test_score =  estimator.score(X_test, y_test)\n",
    "    f1 = f1_score(y_test, estimator.predict(X_test))\n",
    "    \n",
    "    print('Train Accuracy :', estimator.score(X_train, y_train))\n",
    "    print('Test Accuracy:', test_score)\n",
    "    print('Test F1 score:', f1)\n",
    "    score_df.loc[model_label, 'Test_Accuracy'] = test_score\n",
    "    score_df.loc[model_label, 'Test_F1_score'] = f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validate function for printing scores and storing into df.\n",
    "def cv_score(model, X, y, model_label,  cv=5, ):    \n",
    "    \n",
    "    # instantiating model\n",
    "    estimator = model\n",
    "    \n",
    "    cv_result = cross_validate(estimator, X, y, cv = cv, n_jobs=-1, scoring=['accuracy', 'f1'])\n",
    "    \n",
    "    print('Test Accuracy Mean:',cv_result['test_accuracy'].mean())\n",
    "    print('Test Accuracy STD:',cv_result['test_accuracy'].std())\n",
    "    print('Test F1:', cv_result['test_f1'].mean())\n",
    "    score_df.loc[model_label, 'CV_Accuracy'] = cv_result['test_accuracy'].mean()\n",
    "    score_df.loc[model_label, 'CV_Acc_STD'] = cv_result['test_accuracy'].std()\n",
    "    score_df.loc[model_label, 'CV_F1_score'] = cv_result['test_f1'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV function, auto display best score and parameters and storing in df\n",
    "def gridcv(model, X, y, params, cv= 5 ):\n",
    "    \n",
    "    # instantiating model can also be a pipeline\n",
    "    estimator = model\n",
    "    \n",
    "    gridcv = GridSearchCV(estimator=estimator, param_grid=params, cv = cv, verbose=10, n_jobs=6)\n",
    "    gridcv.fit(X, y)\n",
    "    \n",
    "    print(gridcv.best_params_)\n",
    "    print(gridcv.best_score_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = list(nltk.corpus.stopwords.words('english')) + list(string.punctuation) + [\"''\", '``','â€™', \"'s\", \"'d\", \"'ll\", \"'t\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer pipeline and parameters\n",
    "pipeCVNB = Pipeline([('CV',CountVectorizer(stop_words=stopwords)), \n",
    "                    ('NB',MultinomialNB())])\n",
    "\n",
    "paramsCVNB = {'CV__max_df':(1.0, 0.9, 0.8, 0.7),\n",
    "       'CV__min_df': (1, 2, 0.01 , 0.1, 0.2),\n",
    "         'CV__ngram_range':((1,1), (1,2), (1,3))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TfidfVectorizer pipeline and parameters\n",
    "pipeTVNB = Pipeline([('TV',TfidfVectorizer(stop_words=stopwords)), \n",
    "                    ('NB',MultinomialNB())])\n",
    "\n",
    "paramsTVNB = {'TV__max_df':(1.0, 0.9, 0.8, 0.7, 0.6),\n",
    "       'TV__min_df': (1, 2, 0.01, 0.05, 0.1),\n",
    "         'TV__ngram_range':((1,1), (1,2), (1,3), (2,2), (2,3))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Token and Ngram modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Default count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 32.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_raw, X_test_raw=  vect_trans(CountVectorizer(), X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.9350739237089765\n",
      "Test Accuracy: 0.9344135778838762\n",
      "Test F1 score: 0.5646092542896641\n",
      "Test Accuracy Mean: 0.9321614838567932\n",
      "Test Accuracy STD: 0.0005228593021778298\n",
      "Test F1: 0.5489215714930169\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>Test_F1_score</th>\n",
       "      <th>CV_Accuracy</th>\n",
       "      <th>CV_Acc_STD</th>\n",
       "      <th>CV_F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Raw_token_NB</th>\n",
       "      <td>0.934414</td>\n",
       "      <td>0.564609</td>\n",
       "      <td>0.932161</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.548922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Test_Accuracy  Test_F1_score  CV_Accuracy  CV_Acc_STD  \\\n",
       "Raw_token_NB       0.934414       0.564609     0.932161    0.000523   \n",
       "\n",
       "              CV_F1_score  \n",
       "Raw_token_NB     0.548922  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model_label = 'Raw_token_NB'\n",
    "\n",
    "model_score(model, X_train_raw, X_test_raw, y_train, y_test, score_df, model_label)\n",
    "cv_score(model, X_train_raw, y_train, model_label)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.9350739237089765\n",
      "test score: 0.9344135778838762\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_raw, y_train)  \n",
    "test_score =  nb.score(X_test_raw, y_test)\n",
    "print('train score:', nb.score(X_train_raw, y_train))\n",
    "print('test score:', test_score)\n",
    "y_pred = nb.predict(X_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5646092542896641\n",
      "0.7645724512273393\n",
      "0.9344135778838762\n",
      "0.9397915566837656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[291229,  15099],\n",
       "       [  6317,  13886]], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f1_score(y_test, y_pred) )\n",
    "print(f1_score(y_test, y_pred, average='macro') )\n",
    "print(f1_score(y_test, y_pred, average='micro') )\n",
    "print(f1_score(y_test, y_pred, average='weighted') )\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 26.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_t, X_test_t=  vect_trans(CountVectorizer(max_df=1.0, min_df=1, ngram_range=(1,1), \n",
    "                                                    stop_words=stopwords), X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.938349780673771\n",
      "Test Accuracy: 0.9376077615907831\n",
      "Test F1 score: 0.5548150252387299\n",
      "Test Accuracy Mean: 0.9327821506346978\n",
      "Test Accuracy STD: 0.00046156009254156113\n",
      "Test F1: 0.52763522293454\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>Test_F1_score</th>\n",
       "      <th>CV_Accuracy</th>\n",
       "      <th>CV_Acc_STD</th>\n",
       "      <th>CV_F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Raw_token_NB</th>\n",
       "      <td>0.934414</td>\n",
       "      <td>0.564609</td>\n",
       "      <td>0.932161</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.548922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Token_NB</th>\n",
       "      <td>0.937608</td>\n",
       "      <td>0.554815</td>\n",
       "      <td>0.932782</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.527635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Test_Accuracy  Test_F1_score  CV_Accuracy  CV_Acc_STD  \\\n",
       "Raw_token_NB       0.934414       0.564609     0.932161    0.000523   \n",
       "Token_NB           0.937608       0.554815     0.932782    0.000462   \n",
       "\n",
       "              CV_F1_score  \n",
       "Raw_token_NB     0.548922  \n",
       "Token_NB         0.527635  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model_label = 'Token_NB'\n",
    "\n",
    "model_score(model, X_train_t, X_test_t, y_train, y_test, score_df, model_label)\n",
    "cv_score(model, X_train_t, y_train, model_label)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 58.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_bi, X_test_bi=  vect_trans(CountVectorizer(ngram_range=(1,2), stop_words=stopwords), X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.9744383114993911\n",
      "Test Accuracy: 0.9471045628133317\n",
      "Test F1 score: 0.39144528222112607\n",
      "Test Accuracy Mean: 0.9444359946999341\n",
      "Test Accuracy STD: 0.0004057190754223053\n",
      "Test F1: 0.47813979276026675\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>Test_F1_score</th>\n",
       "      <th>CV_Accuracy</th>\n",
       "      <th>CV_Acc_STD</th>\n",
       "      <th>CV_F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Raw_token_NB</th>\n",
       "      <td>0.934414</td>\n",
       "      <td>0.564609</td>\n",
       "      <td>0.932161</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.548922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Token_NB</th>\n",
       "      <td>0.937608</td>\n",
       "      <td>0.554815</td>\n",
       "      <td>0.932782</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.527635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bigram_NB</th>\n",
       "      <td>0.947105</td>\n",
       "      <td>0.391445</td>\n",
       "      <td>0.944436</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.478140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Test_Accuracy  Test_F1_score  CV_Accuracy  CV_Acc_STD  \\\n",
       "Raw_token_NB       0.934414       0.564609     0.932161    0.000523   \n",
       "Token_NB           0.937608       0.554815     0.932782    0.000462   \n",
       "Bigram_NB          0.947105       0.391445     0.944436    0.000406   \n",
       "\n",
       "              CV_F1_score  \n",
       "Raw_token_NB     0.548922  \n",
       "Token_NB         0.527635  \n",
       "Bigram_NB        0.478140  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model_label = 'Bigram_NB'\n",
    "\n",
    "model_score(model, X_train_bi, X_test_bi, y_train, y_test, score_df, model_label)\n",
    "cv_score(model, X_train_bi, y_train, model_label)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# model = RandomForestClassifier(n_estimators= 100, max_depth=20, n_jobs=-1)\n",
    "# model_label = 'Bigram_RF'\n",
    "\n",
    "\n",
    "# model_score(model, X_train_bi, X_test_bi, y_train, y_test, score_df, model_label)\n",
    "# cv_score(model, X_train_bi, y_train, model_label)\n",
    "# score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tri-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_tri, X_test_tri=  vect_trans(CountVectorizer(ngram_range=(1,3), stop_words=stopwords), X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.9880582814664488\n",
      "Test Accuracy: 0.9447341906281487\n",
      "Test F1 score: 0.26915600194394945\n",
      "Test Accuracy Mean: 0.9445962656878848\n",
      "Test Accuracy STD: 0.0004246498388815797\n",
      "Test F1: 0.5055013527650977\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>Test_F1_score</th>\n",
       "      <th>CV_Accuracy</th>\n",
       "      <th>CV_Acc_STD</th>\n",
       "      <th>CV_F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Raw_token_NB</th>\n",
       "      <td>0.934414</td>\n",
       "      <td>0.564609</td>\n",
       "      <td>0.932161</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.548922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Token_NB</th>\n",
       "      <td>0.937608</td>\n",
       "      <td>0.554815</td>\n",
       "      <td>0.932782</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.527635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bigram_NB</th>\n",
       "      <td>0.947105</td>\n",
       "      <td>0.391445</td>\n",
       "      <td>0.944436</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.478140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trigram_NB</th>\n",
       "      <td>0.944734</td>\n",
       "      <td>0.269156</td>\n",
       "      <td>0.944596</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.505501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Test_Accuracy  Test_F1_score  CV_Accuracy  CV_Acc_STD  \\\n",
       "Raw_token_NB       0.934414       0.564609     0.932161    0.000523   \n",
       "Token_NB           0.937608       0.554815     0.932782    0.000462   \n",
       "Bigram_NB          0.947105       0.391445     0.944436    0.000406   \n",
       "Trigram_NB         0.944734       0.269156     0.944596    0.000425   \n",
       "\n",
       "              CV_F1_score  \n",
       "Raw_token_NB     0.548922  \n",
       "Token_NB         0.527635  \n",
       "Bigram_NB        0.478140  \n",
       "Trigram_NB       0.505501  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model_label = 'Trigram_NB'\n",
    "\n",
    "model_score(model, X_train_tri, X_test_tri, y_train, y_test, score_df, model_label)\n",
    "cv_score(model, X_train_tri, y_train, model_label)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# model = RandomForestClassifier(n_estimators= 100, max_depth=20, n_jobs=-1)\n",
    "# model_label = 'Trigram_RF'\n",
    "\n",
    "# model_score(model, X_train_tri, X_test_tri, y_train, y_test, score_df, model_label)\n",
    "# cv_score(model, X_train_tri, y_train, model_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch min/max df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {'CV__max_df':(1.0, 0.9),\n",
    "#        'CV__min_df': (1, 2, 0.01, 0.02),\n",
    "#         'CV__ngram_range':((1,1), (1,2), (1,3))}\n",
    "\n",
    "# gridcv(pipeCVNB, X_train, y_train, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# X_train_t, X_test_t=  vect_trans(CountVectorizer(max_df=1.0, min_df=1, ngram_range=(1,2), \n",
    "#                                                     stop_words=stopwords), X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = MultinomialNB()\n",
    "# model_label = 'Grid_DFNB'\n",
    "\n",
    "# model_score(model, X_train_t, X_test_t, y_train, y_test, score_df, model_label)\n",
    "# cv_score(model, X_train_t, y_train, model_label)\n",
    "# score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tf_t, X_test_tf_t = vect_trans(TfidfTransformer(), X_train_t, X_test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.9426291176623713\n",
      "Test Accuracy: 0.9413470696503548\n",
      "Test F1 score: 0.13276580329650425\n",
      "Test Accuracy Mean: 0.9400800951073152\n",
      "Test Accuracy STD: 0.00015736604219783085\n",
      "Test F1: 0.09913679748013234\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>Test_F1_score</th>\n",
       "      <th>CV_Accuracy</th>\n",
       "      <th>CV_Acc_STD</th>\n",
       "      <th>CV_F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Raw_token_NB</th>\n",
       "      <td>0.934414</td>\n",
       "      <td>0.564609</td>\n",
       "      <td>0.932161</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.548922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Token_NB</th>\n",
       "      <td>0.937608</td>\n",
       "      <td>0.554815</td>\n",
       "      <td>0.932782</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.527635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bigram_NB</th>\n",
       "      <td>0.947105</td>\n",
       "      <td>0.391445</td>\n",
       "      <td>0.944436</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.478140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trigram_NB</th>\n",
       "      <td>0.944734</td>\n",
       "      <td>0.269156</td>\n",
       "      <td>0.944596</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.505501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf_t_NB</th>\n",
       "      <td>0.941347</td>\n",
       "      <td>0.132766</td>\n",
       "      <td>0.940080</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.099137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Test_Accuracy  Test_F1_score  CV_Accuracy  CV_Acc_STD  \\\n",
       "Raw_token_NB       0.934414       0.564609     0.932161    0.000523   \n",
       "Token_NB           0.937608       0.554815     0.932782    0.000462   \n",
       "Bigram_NB          0.947105       0.391445     0.944436    0.000406   \n",
       "Trigram_NB         0.944734       0.269156     0.944596    0.000425   \n",
       "Tfidf_t_NB         0.941347       0.132766     0.940080    0.000157   \n",
       "\n",
       "              CV_F1_score  \n",
       "Raw_token_NB     0.548922  \n",
       "Token_NB         0.527635  \n",
       "Bigram_NB        0.478140  \n",
       "Trigram_NB       0.505501  \n",
       "Tfidf_t_NB       0.099137  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model_label = 'Tfidf_t_NB'\n",
    "\n",
    "model_score(model, X_train_tf_t , X_test_tf_t, y_train, y_test, score_df, model_label)\n",
    "cv_score(model, X_train_tf_t, y_train, model_label)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK Best Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create one list of all question tokens\n",
    "full_text = []\n",
    "\n",
    "for text in X_train:\n",
    "    full_text += [w for w in nltk.word_tokenize(text.lower()) if w not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6390312"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ca', \"n't\"),\n",
       " ('united', 'states'),\n",
       " ('best', 'way'),\n",
       " ('donald', 'trump'),\n",
       " ('year', 'old'),\n",
       " ('computer', 'science'),\n",
       " ('even', 'though'),\n",
       " ('high', 'school'),\n",
       " ('would', 'happen'),\n",
       " ('social', 'media'),\n",
       " ('north', 'korea'),\n",
       " ('pros', 'cons'),\n",
       " ('get', 'rid'),\n",
       " ('major', 'accomplishments'),\n",
       " ('jee', 'mains'),\n",
       " ('look', 'like'),\n",
       " ('wo', \"n't\"),\n",
       " ('would', 'win'),\n",
       " ('new', 'york'),\n",
       " ('machine', 'learning'),\n",
       " ('harry', 'potter'),\n",
       " ('years', 'old'),\n",
       " ('real', 'estate'),\n",
       " ('long', 'take'),\n",
       " ('feel', 'like'),\n",
       " ('saudi', 'arabia'),\n",
       " ('star', 'wars'),\n",
       " ('ssc', 'cgl'),\n",
       " ('mechanical', 'engineering'),\n",
       " ('elon', 'musk'),\n",
       " ('tv', 'show'),\n",
       " ('hillary', 'clinton'),\n",
       " ('hong', 'kong'),\n",
       " ('tamil', 'nadu'),\n",
       " ('president', 'trump'),\n",
       " ('useful', 'tips'),\n",
       " ('san', 'francisco'),\n",
       " ('different', 'types'),\n",
       " ('hotels', 'short-term'),\n",
       " ('artificial', 'intelligence')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create bigram vocabulary\n",
    "bigram_measures = collocations.BigramAssocMeasures()\n",
    "\n",
    "finder = nltk.BigramCollocationFinder.from_words(full_text)\n",
    "# scored = finder.score_ngrams( bigram_measures.likelihood_ratio  )\n",
    "bigram_vocab = finder.nbest(bigram_measures.likelihood_ratio, 40)\n",
    "bigram_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ca', \"n't\")\n",
      "('best', 'way')\n",
      "('year', 'old')\n",
      "('would', 'happen')\n",
      "('united', 'states')\n",
      "('donald', 'trump')\n",
      "('look', 'like')\n",
      "('high', 'school')\n",
      "('feel', 'like')\n",
      "('computer', 'science')\n",
      "('many', 'people')\n",
      "('get', 'rid')\n",
      "('would', 'win')\n",
      "('even', 'though')\n",
      "('social', 'media')\n",
      "('would', 'like')\n",
      "('get', 'job')\n",
      "('long', 'take')\n",
      "('years', 'old')\n",
      "('north', 'korea')\n",
      "(\"n't\", 'want')\n",
      "('wo', \"n't\")\n",
      "(\"n't\", 'know')\n",
      "('people', 'think')\n",
      "('jee', 'mains')\n",
      "('major', 'accomplishments')\n",
      "('best', 'ways')\n",
      "('make', 'money')\n",
      "('much', 'time')\n",
      "('much', 'money')\n"
     ]
    }
   ],
   "source": [
    "# create bigram vocabulary\n",
    "bigram_measures = collocations.BigramAssocMeasures()\n",
    "\n",
    "\n",
    "finder3 = nltk.BigramCollocationFinder.from_words(full_text)\n",
    "finder3.apply_word_filter(lambda x: x in stopwords)\n",
    "scored = finder3.nbest(bigram_measures.raw_freq, 40)\n",
    "for bscore in scored[:30]:\n",
    "    print (bscore)\n",
    "\n",
    "\n",
    "\n",
    "# finder = nltk.BigramCollocationFinder.from_words(full_text)\n",
    "# # scored = finder.score_ngrams( bigram_measures.likelihood_ratio  )\n",
    "# bigram_vocab = finder.nbest(bigram_measures.pmi, 40)\n",
    "# bigram_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ca', \"n't\", 'want'),\n",
       " ('ca', \"n't\", 'know'),\n",
       " ('ca', \"n't\", 'like'),\n",
       " ('ca', \"n't\", 'see'),\n",
       " ('ca', \"n't\", 'understand'),\n",
       " ('ca', \"n't\", 'care'),\n",
       " ('ca', \"n't\", 'afford'),\n",
       " ('ca', \"n't\", 'even'),\n",
       " ('ca', \"n't\", 'get'),\n",
       " ('ca', \"n't\", 'find'),\n",
       " ('ca', \"n't\", 'seem'),\n",
       " ('ca', \"n't\", 'feel'),\n",
       " ('ca', \"n't\", 'exist'),\n",
       " ('ca', \"n't\", 'believe'),\n",
       " ('ca', \"n't\", 'remember'),\n",
       " ('ca', \"n't\", 'let'),\n",
       " ('ca', \"n't\", 'stop'),\n",
       " ('ca', \"n't\", 'talk'),\n",
       " ('ca', \"n't\", 'think'),\n",
       " ('ca', \"n't\", 'would')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create trigram vocabulary\n",
    "trigram_measures = collocations.TrigramAssocMeasures()\n",
    "finder = nltk.TrigramCollocationFinder.from_words(full_text)\n",
    "trigram_vocab = finder.nbest(trigram_measures.likelihood_ratio, 20)\n",
    "trigram_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreate text using ngrams\n",
    "def ngram_to_corpus(df, text_col, ngram_list, n, new_col):\n",
    "#     ngram_list = set({('let', 'us'), ('as', 'soon')})  # {('let', 'us'), ('as', 'soon')}\n",
    "#     tokens = ['please', 'let', 'us', 'know', 'as', 'soon', 'as', 'possible']\n",
    "    new_data = []\n",
    "    for text in df[text_col]:\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        output = []\n",
    "        q_iter = iter(range(len(tokens)))\n",
    "        \n",
    "        for idx in q_iter:\n",
    "            output.append(tokens[idx])\n",
    "            if n == 2:\n",
    "                if idx < (len(tokens) - 1) and (tokens[idx], tokens[idx+1]) in ngram_list:\n",
    "                    output[-1] += '_' + tokens[idx+1]\n",
    "                    next(q_iter)\n",
    "            elif n == 3:\n",
    "                if idx < (len(tokens) - 2) and (tokens[idx], tokens[idx+1], tokens[idx+2] ) in ngram_list:\n",
    "                    output[-1] += '_' + tokens[idx+1] + '_' + tokens[idx+2]\n",
    "                    next(q_iter)\n",
    "                    next(q_iter)\n",
    "        new_data.append( ' '.join(output))\n",
    "    df[new_col] = new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create text with bigram replacement\n",
    "ngram_to_corpus(train, 'question_text', bigram_vocab, 2, 'bigram_question_lkhd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create text with both tri and bigram in text, by applying trigram first\n",
    "ngram_to_corpus(train, 'question_text', trigram_vocab, 3, 'trigram_question_lkhd')\n",
    "ngram_to_corpus(train, 'trigram_question_lkhd', bigram_vocab, 2,  'trigram_question_lkhd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[['bigram_question_lkhd','trigram_question_lkhd']]\n",
    "y = train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=90, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1044897"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram_question_lkhd</th>\n",
       "      <th>trigram_question_lkhd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>488601</th>\n",
       "      <td>How do you respond to a best friend criticisin...</td>\n",
       "      <td>How do you respond to a best friend criticisin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214018</th>\n",
       "      <td>What are some funny excuses that you have come...</td>\n",
       "      <td>What are some funny excuses that you have come...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144139</th>\n",
       "      <td>What laws on the national , state and local le...</td>\n",
       "      <td>What laws on the national , state and local le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694377</th>\n",
       "      <td>If you vote for a democrat because you are a d...</td>\n",
       "      <td>If you vote for a democrat because you are a d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268735</th>\n",
       "      <td>What do you think about the new album of BTS ,...</td>\n",
       "      <td>What do you think about the new album of BTS ,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      bigram_question_lkhd  \\\n",
       "488601   How do you respond to a best friend criticisin...   \n",
       "1214018  What are some funny excuses that you have come...   \n",
       "144139   What laws on the national , state and local le...   \n",
       "694377   If you vote for a democrat because you are a d...   \n",
       "268735   What do you think about the new album of BTS ,...   \n",
       "\n",
       "                                     trigram_question_lkhd  \n",
       "488601   How do you respond to a best friend criticisin...  \n",
       "1214018  What are some funny excuses that you have come...  \n",
       "144139   What laws on the national , state and local le...  \n",
       "694377   If you vote for a democrat because you are a d...  \n",
       "268735   What do you think about the new album of BTS ,...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model using bigram text\n",
    "X_train_bi, X_test_bi =  vect_trans(CountVectorizer(max_df=1.0,  min_df=1, ngram_range=(1,1), stop_words=stopwords),\n",
    "                                   X_train.bigram_question_lkhd, X_test.bigram_question_lkhd,)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1044897x173235 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 6514901 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_bi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<261225x173235 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1604440 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_bi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.9382618573888144\n",
      "Test Accuracy: 0.936824576514499\n",
      "Test F1 score: 0.5497012196785723\n",
      "Test Accuracy Mean: 0.9329656418376958\n",
      "Test Accuracy STD: 0.0005744725754048589\n",
      "Test F1: 0.5304411678616323\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>Test_F1_score</th>\n",
       "      <th>CV_Accuracy</th>\n",
       "      <th>CV_Acc_STD</th>\n",
       "      <th>CV_F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Raw_token_NB</th>\n",
       "      <td>0.934414</td>\n",
       "      <td>0.564609</td>\n",
       "      <td>0.932161</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.548922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Token_NB</th>\n",
       "      <td>0.937608</td>\n",
       "      <td>0.554815</td>\n",
       "      <td>0.932782</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.527635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bigram_NB</th>\n",
       "      <td>0.947105</td>\n",
       "      <td>0.391445</td>\n",
       "      <td>0.944436</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.478140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trigram_NB</th>\n",
       "      <td>0.944734</td>\n",
       "      <td>0.269156</td>\n",
       "      <td>0.944596</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.505501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf_t_NB</th>\n",
       "      <td>0.941347</td>\n",
       "      <td>0.132766</td>\n",
       "      <td>0.940080</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.099137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bigram_best_NB</th>\n",
       "      <td>0.936825</td>\n",
       "      <td>0.549701</td>\n",
       "      <td>0.932966</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.530441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Test_Accuracy  Test_F1_score  CV_Accuracy  CV_Acc_STD  \\\n",
       "Raw_token_NB         0.934414       0.564609     0.932161    0.000523   \n",
       "Token_NB             0.937608       0.554815     0.932782    0.000462   \n",
       "Bigram_NB            0.947105       0.391445     0.944436    0.000406   \n",
       "Trigram_NB           0.944734       0.269156     0.944596    0.000425   \n",
       "Tfidf_t_NB           0.941347       0.132766     0.940080    0.000157   \n",
       "Bigram_best_NB       0.936825       0.549701     0.932966    0.000574   \n",
       "\n",
       "                CV_F1_score  \n",
       "Raw_token_NB       0.548922  \n",
       "Token_NB           0.527635  \n",
       "Bigram_NB          0.478140  \n",
       "Trigram_NB         0.505501  \n",
       "Tfidf_t_NB         0.099137  \n",
       "Bigram_best_NB     0.530441  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model_label = 'Bigram_best_NB'\n",
    "\n",
    "model_score(model, X_train_bi, X_test_bi, y_train, y_test, score_df, model_label)\n",
    "cv_score(model, X_train_bi, y_train, model_label)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model using bigram text\n",
    "X_train_tri, X_test_tri =  vect_trans(CountVectorizer(max_df=1.0,  min_df=1, ngram_range=(1,1), stop_words=stopwords),\n",
    "                                   X_train.trigram_question_lkhd, X_test.trigram_question_lkhd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.9382647284851999\n",
      "Test Accuracy: 0.9368169202794526\n",
      "Test F1 score: 0.5496712231589861\n",
      "Test Accuracy Mean: 0.932959899611036\n",
      "Test Accuracy STD: 0.0005660897195800612\n",
      "Test F1: 0.5304195331100028\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>Test_F1_score</th>\n",
       "      <th>CV_Accuracy</th>\n",
       "      <th>CV_Acc_STD</th>\n",
       "      <th>CV_F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Raw_token_NB</th>\n",
       "      <td>0.934414</td>\n",
       "      <td>0.564609</td>\n",
       "      <td>0.932161</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.548922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Token_NB</th>\n",
       "      <td>0.937608</td>\n",
       "      <td>0.554815</td>\n",
       "      <td>0.932782</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.527635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bigram_NB</th>\n",
       "      <td>0.947105</td>\n",
       "      <td>0.391445</td>\n",
       "      <td>0.944436</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.478140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trigram_NB</th>\n",
       "      <td>0.944734</td>\n",
       "      <td>0.269156</td>\n",
       "      <td>0.944596</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.505501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf_t_NB</th>\n",
       "      <td>0.941347</td>\n",
       "      <td>0.132766</td>\n",
       "      <td>0.940080</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.099137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bigram_best_NB</th>\n",
       "      <td>0.936825</td>\n",
       "      <td>0.549701</td>\n",
       "      <td>0.932966</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.530441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trigram_best_NB</th>\n",
       "      <td>0.936817</td>\n",
       "      <td>0.549671</td>\n",
       "      <td>0.932960</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.530420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Test_Accuracy  Test_F1_score  CV_Accuracy  CV_Acc_STD  \\\n",
       "Raw_token_NB          0.934414       0.564609     0.932161    0.000523   \n",
       "Token_NB              0.937608       0.554815     0.932782    0.000462   \n",
       "Bigram_NB             0.947105       0.391445     0.944436    0.000406   \n",
       "Trigram_NB            0.944734       0.269156     0.944596    0.000425   \n",
       "Tfidf_t_NB            0.941347       0.132766     0.940080    0.000157   \n",
       "Bigram_best_NB        0.936825       0.549701     0.932966    0.000574   \n",
       "Trigram_best_NB       0.936817       0.549671     0.932960    0.000566   \n",
       "\n",
       "                 CV_F1_score  \n",
       "Raw_token_NB        0.548922  \n",
       "Token_NB            0.527635  \n",
       "Bigram_NB           0.478140  \n",
       "Trigram_NB          0.505501  \n",
       "Tfidf_t_NB          0.099137  \n",
       "Bigram_best_NB      0.530441  \n",
       "Trigram_best_NB     0.530420  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model_label = 'Trigram_best_NB'\n",
    "\n",
    "model_score(model, X_train_tri, X_test_tri, y_train, y_test, score_df, model_label)\n",
    "cv_score(model, X_train_tri, y_train, model_label)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
