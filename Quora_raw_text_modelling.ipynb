{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text manipulation\n",
    "import re\n",
    "import string\n",
    "\n",
    "# Data management\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import *\n",
    "import scipy\n",
    "\n",
    "# NLP\n",
    "import nltk\n",
    "import nltk.collocations as collocations\n",
    "from nltk.tag import tnt\n",
    "import spacy\n",
    "\n",
    "# modelling\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "\n",
    "#visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
       "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
       "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
       "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1306122, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of insincere questions: 80810\n",
      "No. of sincere questions: 1225312\n",
      "% of insincere questions: 0.06187017751787352\n",
      "Null score: 0.9381298224821265\n"
     ]
    }
   ],
   "source": [
    "no_insincere = train[train['target']==1].target.count()\n",
    "no_sincere = train[train['target']==0].target.count()\n",
    "\n",
    "print('No. of insincere questions:', no_insincere)\n",
    "print('No. of sincere questions:', no_sincere)\n",
    "print('% of insincere questions:', train.target.mean())\n",
    "print('Null score:', 1- train.target.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of lanuages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lang_list = set([langid.classify(s)[0] for s in train['question_text']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Some are questions in different lanuages, some are questions regarding different lanuages.\n",
    "# basic_stats['no_of_lang'] = len(lang_list)\n",
    "# basic_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.question_text\n",
    "y = train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state = 495)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions and pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vect_trans(vectorizer, X_train, X_test):\n",
    "    # can also take a transformer\n",
    "    vect = vectorizer\n",
    "    vect.fit(X_train)\n",
    "    return vect.transform(X_train), vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultinominalNB function for printing scores and storing into df.\n",
    "def model_score(model, X_train, X_test, y_train, y_test, score_df, model_label):\n",
    "    estimator = model\n",
    "    estimator.fit(X_train, y_train)\n",
    "    test_score =  estimator.score(X_test, y_test)\n",
    "    f1 = f1_score(y_test, estimator.predict(X_test))\n",
    "    \n",
    "    print('Train Accuracy :', estimator.score(X_train, y_train))\n",
    "    print('Test Accuracy:', test_score)\n",
    "    print('Test F1 score:', f1)\n",
    "    score_df.loc[model_label, 'Test_Accuracy'] = test_score\n",
    "    score_df.loc[model_label, 'Test_F1_score'] = f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validate function for printing scores and storing into df.\n",
    "def cv_score(model, X, y, model_label,  cv=5, ):    \n",
    "    \n",
    "    # instantiating model\n",
    "    estimator = model\n",
    "    \n",
    "    cv_result = cross_validate(estimator, X, y, cv = cv, n_jobs=-1, scoring=['accuracy', 'f1'])\n",
    "    \n",
    "    print('Test Accuracy Mean:',cv_result['test_accuracy'].mean())\n",
    "    print('Test Accuracy STD:',cv_result['test_accuracy'].std())\n",
    "    print('Test F1:', cv_result['test_f1'].mean())\n",
    "    score_df.loc[model_label, 'CV_Accuracy'] = cv_result['test_accuracy'].mean()\n",
    "    score_df.loc[model_label, 'CV_Acc_STD'] = cv_result['test_accuracy'].std()\n",
    "    score_df.loc[model_label, 'CV_F1_score'] = cv_result['test_f1'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV function, auto display best score and parameters and storing in df\n",
    "def gridcv(model, X, y, params, cv= 5 ):\n",
    "    \n",
    "    # instantiating model can also be a pipeline\n",
    "    estimator = model\n",
    "    \n",
    "    gridcv = GridSearchCV(estimator=estimator, param_grid=params, cv = cv, verbose=10, n_jobs=6)\n",
    "    gridcv.fit(X, y)\n",
    "    \n",
    "    print(gridcv.best_params_)\n",
    "    print(gridcv.best_score_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = list(nltk.corpus.stopwords.words('english')) + list(string.punctuation) + [\"''\", '``','â€™', \"'s\", \"'d\", \"'ll\", \"'t\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer pipeline and parameters\n",
    "pipeCVNB = Pipeline([('CV',CountVectorizer(stop_words=stopwords)), \n",
    "                    ('NB',MultinomialNB())])\n",
    "\n",
    "paramsCVNB = {'CV__max_df':(1.0, 0.9, 0.8, 0.7),\n",
    "       'CV__min_df': (1, 2, 0.01 , 0.1, 0.2),\n",
    "         'CV__ngram_range':((1,1), (1,2), (1,3))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TfidfVectorizer pipeline and parameters\n",
    "pipeTVNB = Pipeline([('TV',TfidfVectorizer(stop_words=stopwords)), \n",
    "                    ('NB',MultinomialNB())])\n",
    "\n",
    "paramsTVNB = {'TV__max_df':(1.0, 0.9, 0.8, 0.7, 0.6),\n",
    "       'TV__min_df': (1, 2, 0.01, 0.05, 0.1),\n",
    "         'TV__ngram_range':((1,1), (1,2), (1,3), (2,2), (2,3))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Token and Ngram modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Default count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 25.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_raw, X_test_raw=  vect_trans(CountVectorizer(), X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.9350739237089765\n",
      "Test Accuracy: 0.9344135778838762\n",
      "Test F1 score: 0.5646092542896641\n",
      "Test Accuracy Mean: 0.9321614838567932\n",
      "Test Accuracy STD: 0.0005228593021778298\n",
      "Test F1: 0.5489215714930169\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>Test_F1_score</th>\n",
       "      <th>CV_Accuracy</th>\n",
       "      <th>CV_Acc_STD</th>\n",
       "      <th>CV_F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Raw_token_NB</th>\n",
       "      <td>0.934414</td>\n",
       "      <td>0.564609</td>\n",
       "      <td>0.932161</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.548922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Test_Accuracy  Test_F1_score  CV_Accuracy  CV_Acc_STD  \\\n",
       "Raw_token_NB       0.934414       0.564609     0.932161    0.000523   \n",
       "\n",
       "              CV_F1_score  \n",
       "Raw_token_NB     0.548922  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model_label = 'Raw_token_NB'\n",
    "\n",
    "model_score(model, X_train_raw, X_test_raw, y_train, y_test, score_df, model_label)\n",
    "cv_score(model, X_train_raw, y_train, model_label)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.9350739237089765\n",
      "test score: 0.9344135778838762\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_raw, y_train)  \n",
    "test_score =  nb.score(X_test_raw, y_test)\n",
    "print('train score:', nb.score(X_train_raw, y_train))\n",
    "print('test score:', test_score)\n",
    "y_pred = nb.predict(X_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5646092542896641\n",
      "0.7645724512273393\n",
      "0.9344135778838762\n",
      "0.9397915566837656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[291229,  15099],\n",
       "       [  6317,  13886]], dtype=int64)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f1_score(y_test, y_pred) )\n",
    "print(f1_score(y_test, y_pred, average='macro') )\n",
    "print(f1_score(y_test, y_pred, average='micro') )\n",
    "print(f1_score(y_test, y_pred, average='weighted') )\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 23.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_t, X_test_t=  vect_trans(CountVectorizer(max_df=1.0, min_df=1, ngram_range=(1,1), \n",
    "                                                    stop_words=stopwords), X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.938349780673771\n",
      "Test Accuracy: 0.9376077615907831\n",
      "Test F1 score: 0.5548150252387299\n",
      "Test Accuracy Mean: 0.9327821506346978\n",
      "Test Accuracy STD: 0.00046156009254156113\n",
      "Test F1: 0.52763522293454\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>Test_F1_score</th>\n",
       "      <th>CV_Accuracy</th>\n",
       "      <th>CV_Acc_STD</th>\n",
       "      <th>CV_F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Raw_token_NB</th>\n",
       "      <td>0.934414</td>\n",
       "      <td>0.564609</td>\n",
       "      <td>0.932161</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.548922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Token_NB</th>\n",
       "      <td>0.937608</td>\n",
       "      <td>0.554815</td>\n",
       "      <td>0.932782</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.527635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Test_Accuracy  Test_F1_score  CV_Accuracy  CV_Acc_STD  \\\n",
       "Raw_token_NB       0.934414       0.564609     0.932161    0.000523   \n",
       "Token_NB           0.937608       0.554815     0.932782    0.000462   \n",
       "\n",
       "              CV_F1_score  \n",
       "Raw_token_NB     0.548922  \n",
       "Token_NB         0.527635  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model_label = 'Token_NB'\n",
    "\n",
    "model_score(model, X_train_t, X_test_t, y_train, y_test, score_df, model_label)\n",
    "cv_score(model, X_train_t, y_train, model_label)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 53.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_bi, X_test_bi=  vect_trans(CountVectorizer(ngram_range=(1,2), stop_words=stopwords), X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.9744383114993911\n",
      "Test Accuracy: 0.9471045628133317\n",
      "Test F1 score: 0.39144528222112607\n",
      "Test Accuracy Mean: 0.9444359946999341\n",
      "Test Accuracy STD: 0.0004057190754223053\n",
      "Test F1: 0.47813979276026675\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>Test_F1_score</th>\n",
       "      <th>CV_Accuracy</th>\n",
       "      <th>CV_Acc_STD</th>\n",
       "      <th>CV_F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Raw_token_NB</th>\n",
       "      <td>0.934414</td>\n",
       "      <td>0.564609</td>\n",
       "      <td>0.932161</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.548922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Token_NB</th>\n",
       "      <td>0.937608</td>\n",
       "      <td>0.554815</td>\n",
       "      <td>0.932782</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.527635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bigram_NB</th>\n",
       "      <td>0.947105</td>\n",
       "      <td>0.391445</td>\n",
       "      <td>0.944436</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.478140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Test_Accuracy  Test_F1_score  CV_Accuracy  CV_Acc_STD  \\\n",
       "Raw_token_NB       0.934414       0.564609     0.932161    0.000523   \n",
       "Token_NB           0.937608       0.554815     0.932782    0.000462   \n",
       "Bigram_NB          0.947105       0.391445     0.944436    0.000406   \n",
       "\n",
       "              CV_F1_score  \n",
       "Raw_token_NB     0.548922  \n",
       "Token_NB         0.527635  \n",
       "Bigram_NB        0.478140  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model_label = 'Bigram_NB'\n",
    "\n",
    "model_score(model, X_train_bi, X_test_bi, y_train, y_test, score_df, model_label)\n",
    "cv_score(model, X_train_bi, y_train, model_label)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.9381303013196324\n",
      "Test Accuracy: 0.9381283859725417\n",
      "Test F1 score: 0.0\n",
      "Test Accuracy Mean: 0.9381303013270665\n",
      "Test Accuracy STD: 2.2971400212002316e-06\n",
      "Test F1: 0.0\n",
      "Wall time: 20min 51s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# model = RandomForestClassifier(n_estimators= 100, max_depth=20, n_jobs=-1)\n",
    "# model_label = 'Bigram_RF'\n",
    "\n",
    "\n",
    "# model_score(model, X_train_bi, X_test_bi, y_train, y_test, score_df, model_label)\n",
    "# cv_score(model, X_train_bi, y_train, model_label)\n",
    "# score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>Test_F1_score</th>\n",
       "      <th>CV_Accuracy</th>\n",
       "      <th>CV_Acc_STD</th>\n",
       "      <th>CV_F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Raw_token_NB</th>\n",
       "      <td>0.934414</td>\n",
       "      <td>0.564609</td>\n",
       "      <td>0.932161</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.548922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Token_NB</th>\n",
       "      <td>0.937608</td>\n",
       "      <td>0.554815</td>\n",
       "      <td>0.932782</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.527635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bigram_NB</th>\n",
       "      <td>0.947105</td>\n",
       "      <td>0.391445</td>\n",
       "      <td>0.944436</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.478140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bigram_RF</th>\n",
       "      <td>0.938128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.938130</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Test_Accuracy  Test_F1_score  CV_Accuracy  CV_Acc_STD  \\\n",
       "Raw_token_NB       0.934414       0.564609     0.932161    0.000523   \n",
       "Token_NB           0.937608       0.554815     0.932782    0.000462   \n",
       "Bigram_NB          0.947105       0.391445     0.944436    0.000406   \n",
       "Bigram_RF          0.938128       0.000000     0.938130    0.000002   \n",
       "\n",
       "              CV_F1_score  \n",
       "Raw_token_NB     0.548922  \n",
       "Token_NB         0.527635  \n",
       "Bigram_NB        0.478140  \n",
       "Bigram_RF        0.000000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tri-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_tri, X_test_tri=  vect_trans(CountVectorizer(ngram_range=(1,3), stop_words=stopwords), X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.9880582814664488\n",
      "Test Accuracy: 0.9447341906281487\n",
      "Test F1 score: 0.26915600194394945\n",
      "Test Accuracy Mean: 0.9445962656878848\n",
      "Test Accuracy STD: 0.0004246498388815797\n",
      "Test F1: 0.5055013527650977\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>Test_F1_score</th>\n",
       "      <th>CV_Accuracy</th>\n",
       "      <th>CV_Acc_STD</th>\n",
       "      <th>CV_F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Raw_token_NB</th>\n",
       "      <td>0.934414</td>\n",
       "      <td>0.564609</td>\n",
       "      <td>0.932161</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.548922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Token_NB</th>\n",
       "      <td>0.937608</td>\n",
       "      <td>0.554815</td>\n",
       "      <td>0.932782</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.527635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bigram_NB</th>\n",
       "      <td>0.947105</td>\n",
       "      <td>0.391445</td>\n",
       "      <td>0.944436</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.478140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bigram_RF</th>\n",
       "      <td>0.938128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.938130</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trigram_NB</th>\n",
       "      <td>0.944734</td>\n",
       "      <td>0.269156</td>\n",
       "      <td>0.944596</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.505501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Test_Accuracy  Test_F1_score  CV_Accuracy  CV_Acc_STD  \\\n",
       "Raw_token_NB       0.934414       0.564609     0.932161    0.000523   \n",
       "Token_NB           0.937608       0.554815     0.932782    0.000462   \n",
       "Bigram_NB          0.947105       0.391445     0.944436    0.000406   \n",
       "Bigram_RF          0.938128       0.000000     0.938130    0.000002   \n",
       "Trigram_NB         0.944734       0.269156     0.944596    0.000425   \n",
       "\n",
       "              CV_F1_score  \n",
       "Raw_token_NB     0.548922  \n",
       "Token_NB         0.527635  \n",
       "Bigram_NB        0.478140  \n",
       "Bigram_RF        0.000000  \n",
       "Trigram_NB       0.505501  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model_label = 'Trigram_NB'\n",
    "\n",
    "model_score(model, X_train_tri, X_test_tri, y_train, y_test, score_df, model_label)\n",
    "cv_score(model, X_train_tri, y_train, model_label)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.9381303013196324\n",
      "Test Accuracy: 0.9381283859725417\n",
      "Test F1 score: 0.0\n",
      "Test Accuracy Mean: 0.9381303013270665\n",
      "Test Accuracy STD: 2.2971400212002316e-06\n",
      "Test F1: 0.0\n",
      "Wall time: 32min 27s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# model = RandomForestClassifier(n_estimators= 100, max_depth=20, n_jobs=-1)\n",
    "# model_label = 'Trigram_RF'\n",
    "\n",
    "# model_score(model, X_train_tri, X_test_tri, y_train, y_test, score_df, model_label)\n",
    "# cv_score(model, X_train_tri, y_train, model_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>Test_F1_score</th>\n",
       "      <th>CV_Accuracy</th>\n",
       "      <th>CV_Acc_STD</th>\n",
       "      <th>CV_F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Raw_token_NB</th>\n",
       "      <td>0.934414</td>\n",
       "      <td>0.564609</td>\n",
       "      <td>0.932161</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.548922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Token_NB</th>\n",
       "      <td>0.937608</td>\n",
       "      <td>0.554815</td>\n",
       "      <td>0.932782</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.527635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bigram_NB</th>\n",
       "      <td>0.947105</td>\n",
       "      <td>0.391445</td>\n",
       "      <td>0.944436</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.478140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bigram_RF</th>\n",
       "      <td>0.938128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.938130</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trigram_NB</th>\n",
       "      <td>0.944734</td>\n",
       "      <td>0.269156</td>\n",
       "      <td>0.944596</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.505501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trigram_RF</th>\n",
       "      <td>0.938128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.938130</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Test_Accuracy  Test_F1_score  CV_Accuracy  CV_Acc_STD  \\\n",
       "Raw_token_NB       0.934414       0.564609     0.932161    0.000523   \n",
       "Token_NB           0.937608       0.554815     0.932782    0.000462   \n",
       "Bigram_NB          0.947105       0.391445     0.944436    0.000406   \n",
       "Bigram_RF          0.938128       0.000000     0.938130    0.000002   \n",
       "Trigram_NB         0.944734       0.269156     0.944596    0.000425   \n",
       "Trigram_RF         0.938128       0.000000     0.938130    0.000002   \n",
       "\n",
       "              CV_F1_score  \n",
       "Raw_token_NB     0.548922  \n",
       "Token_NB         0.527635  \n",
       "Bigram_NB        0.478140  \n",
       "Bigram_RF        0.000000  \n",
       "Trigram_NB       0.505501  \n",
       "Trigram_RF       0.000000  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch min/max df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   1 tasks      | elapsed:   22.2s\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:   54.8s\n",
      "[Parallel(n_jobs=6)]: Done  13 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=6)]: Done  20 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=6)]: Done  29 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=6)]: Done  49 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=6)]: Done  60 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=6)]: Done  73 tasks      | elapsed: 10.1min\n",
      "[Parallel(n_jobs=6)]: Done  86 tasks      | elapsed: 11.8min\n",
      "[Parallel(n_jobs=6)]: Done 101 tasks      | elapsed: 13.7min\n",
      "[Parallel(n_jobs=6)]: Done 120 out of 120 | elapsed: 16.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CV__max_df': 1.0, 'CV__min_df': 1, 'CV__ngram_range': (1, 2)}\n",
      "0.9460979122919667\n"
     ]
    }
   ],
   "source": [
    "# params = {'CV__max_df':(1.0, 0.9),\n",
    "#        'CV__min_df': (1, 2, 0.01, 0.02),\n",
    "#         'CV__ngram_range':((1,1), (1,2), (1,3))}\n",
    "\n",
    "# gridcv(pipeCVNB, X_train, y_train, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 52.3 s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# X_train_t, X_test_t=  vect_trans(CountVectorizer(max_df=1.0, min_df=1, ngram_range=(1,2), \n",
    "#                                                     stop_words=stopwords), X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.9744383114993911\n",
      "test score: 0.9471045628133317\n",
      "Test Accuracy Mean: 0.9444359946999341\n",
      "Test Accuracy STD: 0.0004057190754223053\n",
      "Test F1: 0.47813979276026675\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_score</th>\n",
       "      <th>CV_Accuracy</th>\n",
       "      <th>CV_Acc_STD</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>token_NB</th>\n",
       "      <td>0.934414</td>\n",
       "      <td>0.932161</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.548922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stop_token_NB</th>\n",
       "      <td>0.937608</td>\n",
       "      <td>0.932782</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.527635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stop_bi_NB</th>\n",
       "      <td>0.947105</td>\n",
       "      <td>0.944436</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.478140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stop_bi_RF</th>\n",
       "      <td>0.938128</td>\n",
       "      <td>0.944436</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.478140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stop_tri_NB</th>\n",
       "      <td>0.944734</td>\n",
       "      <td>0.944596</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.505501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stop_tri_RF</th>\n",
       "      <td>0.938128</td>\n",
       "      <td>0.944596</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.505501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stop_df_NB</th>\n",
       "      <td>0.947105</td>\n",
       "      <td>0.944436</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.478140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Test_score  CV_Accuracy  CV_Acc_STD  F1_score\n",
       "token_NB         0.934414     0.932161    0.000523  0.548922\n",
       "stop_token_NB    0.937608     0.932782    0.000462  0.527635\n",
       "stop_bi_NB       0.947105     0.944436    0.000406  0.478140\n",
       "stop_bi_RF       0.938128     0.944436    0.000406  0.478140\n",
       "stop_tri_NB      0.944734     0.944596    0.000425  0.505501\n",
       "stop_tri_RF      0.938128     0.944596    0.000425  0.505501\n",
       "stop_df_NB       0.947105     0.944436    0.000406  0.478140"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = MultinomialNB()\n",
    "# model_label = 'Grid_DFNB'\n",
    "\n",
    "# model_score(model, X_train_t, X_test_t, y_train, y_test, score_df, model_label)\n",
    "# cv_score(model, X_train_t, y_train, model_label)\n",
    "# score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tf_t, X_test_tf_t = vect_trans(TfidfTransformer(), X_train_t, X_test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.9426291176623713\n",
      "Test Accuracy: 0.9413470696503548\n",
      "Test F1 score: 0.13276580329650425\n",
      "Test Accuracy Mean: 0.9400800951073152\n",
      "Test Accuracy STD: 0.00015736604219783085\n",
      "Test F1: 0.09913679748013234\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>Test_F1_score</th>\n",
       "      <th>CV_Accuracy</th>\n",
       "      <th>CV_Acc_STD</th>\n",
       "      <th>CV_F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Raw_token_NB</th>\n",
       "      <td>0.934414</td>\n",
       "      <td>0.564609</td>\n",
       "      <td>0.932161</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.548922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Token_NB</th>\n",
       "      <td>0.937608</td>\n",
       "      <td>0.554815</td>\n",
       "      <td>0.932782</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.527635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bigram_NB</th>\n",
       "      <td>0.947105</td>\n",
       "      <td>0.391445</td>\n",
       "      <td>0.944436</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.478140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bigram_RF</th>\n",
       "      <td>0.938128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.938130</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trigram_NB</th>\n",
       "      <td>0.944734</td>\n",
       "      <td>0.269156</td>\n",
       "      <td>0.944596</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.505501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trigram_RF</th>\n",
       "      <td>0.938128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.938130</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf_t_NB</th>\n",
       "      <td>0.941347</td>\n",
       "      <td>0.132766</td>\n",
       "      <td>0.940080</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.099137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Test_Accuracy  Test_F1_score  CV_Accuracy  CV_Acc_STD  \\\n",
       "Raw_token_NB       0.934414       0.564609     0.932161    0.000523   \n",
       "Token_NB           0.937608       0.554815     0.932782    0.000462   \n",
       "Bigram_NB          0.947105       0.391445     0.944436    0.000406   \n",
       "Bigram_RF          0.938128       0.000000     0.938130    0.000002   \n",
       "Trigram_NB         0.944734       0.269156     0.944596    0.000425   \n",
       "Trigram_RF         0.938128       0.000000     0.938130    0.000002   \n",
       "Tfidf_t_NB         0.941347       0.132766     0.940080    0.000157   \n",
       "\n",
       "              CV_F1_score  \n",
       "Raw_token_NB     0.548922  \n",
       "Token_NB         0.527635  \n",
       "Bigram_NB        0.478140  \n",
       "Bigram_RF        0.000000  \n",
       "Trigram_NB       0.505501  \n",
       "Trigram_RF       0.000000  \n",
       "Tfidf_t_NB       0.099137  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model_label = 'Tfidf_t_NB'\n",
    "\n",
    "model_score(model, X_train_tf_t , X_test_tf_t, y_train, y_test, score_df, model_label)\n",
    "cv_score(model, X_train_tf_t, y_train, model_label)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK Best Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create one list of all question tokens\n",
    "full_text = []\n",
    "\n",
    "for text in X_train:\n",
    "    full_text += [w for w in nltk.word_tokenize(text.lower()) if w not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6390312"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ca', \"n't\"),\n",
       " ('united', 'states'),\n",
       " ('best', 'way'),\n",
       " ('donald', 'trump'),\n",
       " ('year', 'old'),\n",
       " ('computer', 'science'),\n",
       " ('even', 'though'),\n",
       " ('high', 'school'),\n",
       " ('would', 'happen'),\n",
       " ('social', 'media'),\n",
       " ('north', 'korea'),\n",
       " ('pros', 'cons'),\n",
       " ('get', 'rid'),\n",
       " ('major', 'accomplishments'),\n",
       " ('jee', 'mains'),\n",
       " ('look', 'like'),\n",
       " ('wo', \"n't\"),\n",
       " ('would', 'win'),\n",
       " ('new', 'york'),\n",
       " ('machine', 'learning'),\n",
       " ('harry', 'potter'),\n",
       " ('years', 'old'),\n",
       " ('real', 'estate'),\n",
       " ('long', 'take'),\n",
       " ('feel', 'like'),\n",
       " ('saudi', 'arabia'),\n",
       " ('star', 'wars'),\n",
       " ('ssc', 'cgl'),\n",
       " ('mechanical', 'engineering'),\n",
       " ('elon', 'musk'),\n",
       " ('tv', 'show'),\n",
       " ('hillary', 'clinton'),\n",
       " ('hong', 'kong'),\n",
       " ('tamil', 'nadu'),\n",
       " ('president', 'trump'),\n",
       " ('useful', 'tips'),\n",
       " ('san', 'francisco'),\n",
       " ('different', 'types'),\n",
       " ('hotels', 'short-term'),\n",
       " ('artificial', 'intelligence')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create bigram vocabulary\n",
    "bigram_measures = collocations.BigramAssocMeasures()\n",
    "\n",
    "finder = nltk.BigramCollocationFinder.from_words(full_text)\n",
    "# scored = finder.score_ngrams( bigram_measures.likelihood_ratio  )\n",
    "bigram_vocab = finder.nbest(bigram_measures.likelihood_ratio, 40)\n",
    "bigram_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('\\x02tÃ±\\x7fÂ¼Ã©\\x1aaÃ¹Ãµ\\x8dÂ¶rwÃ¬iÃ¬Ã±Ã³', '\\x10Å“Ã¸'), 22.60745494022481)\n",
      "(('\\x10Å“Ã¸', '\\x17'), 22.60745494022481)\n",
      "(('\\x17', 'y.Â¾Æ’e'), 22.60745494022481)\n",
      "((\"'07\", \"'08\"), 22.60745494022481)\n",
      "((\"'20s\", \"'30s\"), 22.60745494022481)\n",
      "((\"'24-jan-2018\", \"'24/01/2018\"), 22.60745494022481)\n",
      "((\"'42\", 'salko'), 22.60745494022481)\n",
      "((\"'acclaimed\", 'musician/'), 22.60745494022481)\n",
      "((\"'adiye\", 'manam'), 22.60745494022481)\n",
      "((\"'afflict\", \"'inflict\"), 22.60745494022481)\n",
      "((\"'allegretto\", 'tranquillo'), 22.60745494022481)\n",
      "((\"'amar\", 'maruf'), 22.60745494022481)\n",
      "((\"'anekantwad\", \"'syadvada\"), 22.60745494022481)\n",
      "((\"'anger\", \"'anticipation\"), 22.60745494022481)\n",
      "((\"'annum\", \"'year\"), 22.60745494022481)\n",
      "((\"'anti-fracking\", 'anti-pipeline'), 22.60745494022481)\n",
      "((\"'anyway\", \"'anyways\"), 22.60745494022481)\n",
      "((\"'apoapsis\", \"'periapsis\"), 22.60745494022481)\n",
      "((\"'ass\", \"'fuck\"), 22.60745494022481)\n",
      "((\"'association\", \"'sponsors\"), 22.60745494022481)\n",
      "((\"'audacious\", \"'audacity\"), 22.60745494022481)\n",
      "((\"'babu\", \"'shona\"), 22.60745494022481)\n",
      "((\"'baklava\", \"'balaclava\"), 22.60745494022481)\n",
      "((\"'baniya\", \"'ambani\"), 22.60745494022481)\n",
      "((\"'bet\", \"'cast\"), 22.60745494022481)\n",
      "((\"'bhakt\", \"'chamcha\"), 22.60745494022481)\n",
      "((\"'bheege\", 'honth'), 22.60745494022481)\n",
      "((\"'blinded\", 'beleif'), 22.60745494022481)\n",
      "((\"'boobs\", \"'dupatta\"), 22.60745494022481)\n",
      "((\"'butt\", \"'ass\"), 22.60745494022481)\n"
     ]
    }
   ],
   "source": [
    "# create bigram vocabulary\n",
    "bigram_measures = collocations.BigramAssocMeasures()\n",
    "\n",
    "\n",
    "finder3 = nltk.BigramCollocationFinder.from_words(full_text)\n",
    "finder3.apply_word_filter(lambda x: x in stopwords)\n",
    "scored = finder3.score_ngrams(bigram_measures.pmi)\n",
    "for bscore in scored[:30]:\n",
    "    print (bscore)\n",
    "\n",
    "\n",
    "\n",
    "# finder = nltk.BigramCollocationFinder.from_words(full_text)\n",
    "# # scored = finder.score_ngrams( bigram_measures.likelihood_ratio  )\n",
    "# bigram_vocab = finder.nbest(bigram_measures.pmi, 40)\n",
    "# bigram_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ca', \"n't\", 'want'),\n",
       " ('ca', \"n't\", 'know'),\n",
       " ('ca', \"n't\", 'like'),\n",
       " ('ca', \"n't\", 'see'),\n",
       " ('ca', \"n't\", 'understand'),\n",
       " ('ca', \"n't\", 'care'),\n",
       " ('ca', \"n't\", 'afford'),\n",
       " ('ca', \"n't\", 'even'),\n",
       " ('ca', \"n't\", 'get'),\n",
       " ('ca', \"n't\", 'find'),\n",
       " ('ca', \"n't\", 'seem'),\n",
       " ('ca', \"n't\", 'feel'),\n",
       " ('ca', \"n't\", 'exist'),\n",
       " ('ca', \"n't\", 'believe'),\n",
       " ('ca', \"n't\", 'remember'),\n",
       " ('ca', \"n't\", 'let'),\n",
       " ('ca', \"n't\", 'stop'),\n",
       " ('ca', \"n't\", 'talk'),\n",
       " ('ca', \"n't\", 'think'),\n",
       " ('ca', \"n't\", 'would')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create trigram vocabulary\n",
    "trigram_measures = collocations.TrigramAssocMeasures()\n",
    "finder = nltk.TrigramCollocationFinder.from_words(full_text)\n",
    "trigram_vocab = finder.nbest(trigram_measures.likelihood_ratio, 20)\n",
    "trigram_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreate text using ngrams\n",
    "def ngram_to_corpus(df, text_col, ngram_list, n, new_col):\n",
    "#     ngram_list = set({('let', 'us'), ('as', 'soon')})  # {('let', 'us'), ('as', 'soon')}\n",
    "#     tokens = ['please', 'let', 'us', 'know', 'as', 'soon', 'as', 'possible']\n",
    "    new_data = []\n",
    "    for text in df[text_col]:\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        output = []\n",
    "        q_iter = iter(range(len(tokens)))\n",
    "        \n",
    "        for idx in q_iter:\n",
    "            output.append(tokens[idx])\n",
    "            if n == 2:\n",
    "                if idx < (len(tokens) - 1) and (tokens[idx], tokens[idx+1]) in ngram_list:\n",
    "                    output[-1] += '_' + tokens[idx+1]\n",
    "                    next(q_iter)\n",
    "            elif n == 3:\n",
    "                if idx < (len(tokens) - 2) and (tokens[idx], tokens[idx+1], tokens[idx+2] ) in ngram_list:\n",
    "                    output[-1] += '_' + tokens[idx+1] + '_' + tokens[idx+2]\n",
    "                    next(q_iter)\n",
    "                    next(q_iter)\n",
    "        new_data.append( ' '.join(output))\n",
    "    df[new_col] = new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create text with bigram replacement\n",
    "ngram_to_corpus(train, 'question_text', bigram_vocab, 2, 'bigram_question_lkhd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create text with both tri and bigram in text, by applying trigram first\n",
    "ngram_to_corpus(train, 'question_text', trigram_vocab, 3, 'trigram_question_lkhd')\n",
    "ngram_to_corpus(train, 'question_text', bigram_vocab, 2,  'trigram_question_lkhd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[['bigram_question_lkhd','trigram_question_lkhd']]\n",
    "y = train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X.bigram_question_lkhd, y, stratify=y, random_state=90, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "979591"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model using bigram text\n",
    "X_train_bi, X_test_bi =  vect_trans(CountVectorizer(max_df=1.0,  min_df=1, ngram_range=(1,1), stop_words=stopwords),\n",
    "                                   X_train, X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.9382494159711435\n",
      "Test Accuracy: 0.9367671547516508\n",
      "Test F1 score: 0.5494517484043423\n",
      "Test Accuracy Mean: 0.9328833372193556\n",
      "Test Accuracy STD: 0.0006104877418906132\n",
      "Test F1: 0.530024023014736\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>Test_F1_score</th>\n",
       "      <th>CV_Accuracy</th>\n",
       "      <th>CV_Acc_STD</th>\n",
       "      <th>CV_F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Raw_token_NB</th>\n",
       "      <td>0.934414</td>\n",
       "      <td>0.564609</td>\n",
       "      <td>0.932161</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.548922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Token_NB</th>\n",
       "      <td>0.937608</td>\n",
       "      <td>0.554815</td>\n",
       "      <td>0.932782</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.527635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bigram_NB</th>\n",
       "      <td>0.947105</td>\n",
       "      <td>0.391445</td>\n",
       "      <td>0.944436</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.478140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bigram_RF</th>\n",
       "      <td>0.938128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.938130</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trigram_NB</th>\n",
       "      <td>0.944734</td>\n",
       "      <td>0.269156</td>\n",
       "      <td>0.944596</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.505501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trigram_RF</th>\n",
       "      <td>0.938128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.938130</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf_t_NB</th>\n",
       "      <td>0.941347</td>\n",
       "      <td>0.132766</td>\n",
       "      <td>0.940080</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.099137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bigram_best_NB</th>\n",
       "      <td>0.936767</td>\n",
       "      <td>0.549452</td>\n",
       "      <td>0.932883</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0.530024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Test_Accuracy  Test_F1_score  CV_Accuracy  CV_Acc_STD  \\\n",
       "Raw_token_NB         0.934414       0.564609     0.932161    0.000523   \n",
       "Token_NB             0.937608       0.554815     0.932782    0.000462   \n",
       "Bigram_NB            0.947105       0.391445     0.944436    0.000406   \n",
       "Bigram_RF            0.938128       0.000000     0.938130    0.000002   \n",
       "Trigram_NB           0.944734       0.269156     0.944596    0.000425   \n",
       "Trigram_RF           0.938128       0.000000     0.938130    0.000002   \n",
       "Tfidf_t_NB           0.941347       0.132766     0.940080    0.000157   \n",
       "Bigram_best_NB       0.936767       0.549452     0.932883    0.000610   \n",
       "\n",
       "                CV_F1_score  \n",
       "Raw_token_NB       0.548922  \n",
       "Token_NB           0.527635  \n",
       "Bigram_NB          0.478140  \n",
       "Bigram_RF          0.000000  \n",
       "Trigram_NB         0.505501  \n",
       "Trigram_RF         0.000000  \n",
       "Tfidf_t_NB         0.099137  \n",
       "Bigram_best_NB     0.530024  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model_label = 'Bigram_best_NB'\n",
    "\n",
    "model_score(model, X_train_bi, X_test_bi, y_train, y_test, score_df, model_label)\n",
    "cv_score(model, X_train_bi, y_train, model_label)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
